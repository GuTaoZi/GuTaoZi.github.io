<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"gutaozi.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":-1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"slideLeftBigIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Notes on PRML">
<meta property="og:type" content="article">
<meta property="og:title" content="CS329 Machine Learning Notes">
<meta property="og:url" content="https://gutaozi.github.io/2023/09/12/CS329_Notes/index.html">
<meta property="og:site_name" content="咕桃w！">
<meta property="og:description" content="Notes on PRML">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://s2.loli.net/2023/10/08/sa2LJItkVQEUCeS.png">
<meta property="og:image" content="https://s2.loli.net/2023/10/08/QfxjJAYzwHd8TVe.png">
<meta property="og:image" content="https://s2.loli.net/2023/10/08/frI2BYLVbCgKNkc.png">
<meta property="og:image" content="https://s2.loli.net/2023/10/08/Edem7OF3T8hXSaU.png">
<meta property="og:image" content="https://s2.loli.net/2023/10/08/YCeVcwDHuzB4i3k.png">
<meta property="og:image" content="https://s2.loli.net/2023/10/08/yoqniUgpIN5b71F.png">
<meta property="og:image" content="https://s2.loli.net/2023/10/08/sF7Khkg2mebAyVP.png">
<meta property="og:image" content="https://s2.loli.net/2023/10/08/sq5Oz4LW1bVXuvG.png">
<meta property="og:image" content="https://picst.sunbangyan.cn/2023/11/21/d15a31fe2fd078f7148522e283831252.jpeg">
<meta property="og:image" content="https://s2.loli.net/2023/11/07/bdLjc4yTiRkGEI7.png">
<meta property="og:image" content="https://raw.githubusercontent.com/GuTaoZi/CS329_Machine_Learning/daad03239f0966cd39434cf8312ce640a226cb1f/Lab_Materials/Lab06.Linear%20Discriminant%20Analysis/images/example.png">
<meta property="og:image" content="https://s2.loli.net/2023/01/01/8pS9IbAPfWXDOgt.png">
<meta property="article:published_time" content="2023-09-12T02:20:32.703Z">
<meta property="article:modified_time" content="2023-12-25T15:13:26.905Z">
<meta property="article:author" content="咕桃">
<meta property="article:tag" content="Machine Learning">
<meta property="article:tag" content="Artificial Intelligence">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2023/10/08/sa2LJItkVQEUCeS.png">

<link rel="canonical" href="https://gutaozi.github.io/2023/09/12/CS329_Notes/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>CS329 Machine Learning Notes | 咕桃w！</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>


</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">咕桃w！</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://gutaozi.github.io/2023/09/12/CS329_Notes/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars.githubusercontent.com/u/109007949?v=4">
      <meta itemprop="name" content="咕桃">
      <meta itemprop="description" content="Just Do It, But Not Just Do It.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="咕桃w！">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          CS329 Machine Learning Notes
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-09-12 10:20:32" itemprop="dateCreated datePublished" datetime="2023-09-12T10:20:32+08:00">2023-09-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-12-25 23:13:26" itemprop="dateModified" datetime="2023-12-25T23:13:26+08:00">2023-12-25</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CS/" itemprop="url" rel="index"><span itemprop="name">CS</span></a>
                </span>
            </span>

          
            <div class="post-description">Notes on PRML</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="Outline"><a href="#Outline" class="headerlink" title="Outline"></a>Outline</h2><ol>
<li>Introduction</li>
<li>Preliminary</li>
<li>Distributions</li>
<li>Linear Models for Regression</li>
<li>Linear Models for Classification</li>
<li>Neural Networks</li>
<li>Sparse Kernel Machines</li>
<li>Mixture Models and EM Learning</li>
<li>Sequential Data</li>
</ol>
<h2 id="Chapter-1-Introduction"><a href="#Chapter-1-Introduction" class="headerlink" title="Chapter 1 - Introduction"></a>Chapter 1 - Introduction</h2><h3 id="Concepts"><a href="#Concepts" class="headerlink" title="Concepts"></a>Concepts</h3><ul>
<li><strong>Machine Learning</strong>—minimization of some loss function for generalizing data sets with models.</li>
<li><strong>Datasets</strong>—annotated, indexed, organized</li>
<li><strong>Models</strong>—tree, distance, probabilistic, graph, bio-inspired</li>
<li><strong>Optimization</strong>—algorithms can minimize the loss</li>
</ul>
<h3 id="Linear-Optimization-Model"><a href="#Linear-Optimization-Model" class="headerlink" title="Linear Optimization Model"></a>Linear Optimization Model</h3><script type="math/tex; mode=display">
Y=AX+W,\quad W\sim \mathbf N(0,R)\\
L(x)=\frac 1 2 (Y-AX)^\text TR^{-1}(Y-AX)\\</script><p>Find $X^\star$ to minimize the loss function:</p>
<script type="math/tex; mode=display">
\begin{align*}
&X^\star=\min\limits_X(Y-AX)^\text TR^{-1}(Y-AX)\\
&\text {Let } \frac{\partial}{\partial X^\text T}(Y-AX)^\text TR^{-1}(Y-AX)=0\\
&\Rightarrow X^\star = (A^\text T R^{-1}A)A^{\text T}R^{-1}Y
\end{align*}</script><h3 id="Euclidean-Distance-Optimization"><a href="#Euclidean-Distance-Optimization" class="headerlink" title="Euclidean Distance Optimization"></a>Euclidean Distance Optimization</h3><p>Point $x_0$, model $\mathbf b^\text Tx=d$.</p>
<script type="math/tex; mode=display">
x^\star = \min\limits_{x}(x-x_0)^\text T(x-x_0), \text{s.t.}\ \mathbf{b}^\text Tx-d=0</script><p>We have:</p>
<script type="math/tex; mode=display">
\begin{align*}
d&=\mathbf b^\text T(x_0-\lambda \mathbf b)\\
\lambda &= \frac{\mathbf b^\text Tx_0-d}{\mathbf b^\text T\mathbf b}
\end{align*}</script><p>Lagrange optimization:</p>
<script type="math/tex; mode=display">
\begin{align*}
L(x,\lambda)&=\frac 1 2 (x-x_0)^\text T(x-x_0)+\lambda(\mathbf b^\text Tx-d)\\
\frac{\partial L}{\partial x^\text T}&=x^\star-x_0+\lambda \mathbf b=0\\
x^\star&=x_0-\frac{(\mathbf b^\text Tx_0-d)\mathbf b}{\mathbf b^\text T\mathbf b}
\end{align*}</script><h3 id="Convex-Optimization"><a href="#Convex-Optimization" class="headerlink" title="Convex Optimization"></a>Convex Optimization</h3><h4 id="Unconstrained-optimization"><a href="#Unconstrained-optimization" class="headerlink" title="Unconstrained optimization"></a>Unconstrained optimization</h4><h5 id="Gradient-descent"><a href="#Gradient-descent" class="headerlink" title="Gradient descent"></a>Gradient descent</h5><script type="math/tex; mode=display">
f(x_{t+1})=f(x_t)-\eta\nabla f(x_t)^\text T(x-x_t)</script><h5 id="Gauss-Newton’s-Method"><a href="#Gauss-Newton’s-Method" class="headerlink" title="Gauss-Newton’s Method"></a>Gauss-Newton’s Method</h5><p>Use a second-order approximation to function:</p>
<script type="math/tex; mode=display">
f(x+\Delta x)\approx f(x)+\nabla f(x)^\text T\Delta x+\frac 1 2 \Delta x^\text T\nabla^2f(x)\Delta x</script><p>Choose $\Delta x$ to minimize above:</p>
<script type="math/tex; mode=display">
\Delta x=-[\nabla^2f(x)]^{-1}\nabla f(x)</script><p>Descent direction:</p>
<script type="math/tex; mode=display">
\nabla f(x)^\text T\Delta x= -\nabla f(x)^\text T[\nabla^2f(x)]^{-1}\nabla f(x)<0</script><h5 id="Batch-Gradient-Descent"><a href="#Batch-Gradient-Descent" class="headerlink" title="Batch Gradient Descent"></a>Batch Gradient Descent</h5><p>Minimize empirical loss, assuming it’s convex and unconstrained.</p>
<ul>
<li>Gradient descent on the empirical loss</li>
<li>Gradient is the average of the gradient for all samples</li>
<li>Very slow when $n$ is very large</li>
</ul>
<script type="math/tex; mode=display">
w^{k+1}\leftarrow w^k-\eta_t(\frac1 n \sum\limits_{i=1}^n\frac{\partial L(w,x_i,y_i)}{\partial w})</script><h5 id="Stochastic-Gradient-Descent"><a href="#Stochastic-Gradient-Descent" class="headerlink" title="Stochastic Gradient Descent"></a>Stochastic Gradient Descent</h5><p>Compute gradient from just one or a few samples</p>
<script type="math/tex; mode=display">
w^{k+1}\leftarrow w^k-\eta_t \frac{\partial L(w,x_i,y_i)}{\partial w}</script><h4 id="Constrained-optimization"><a href="#Constrained-optimization" class="headerlink" title="Constrained optimization"></a>Constrained optimization</h4><ul>
<li>Lagrange methods</li>
<li>Bayesian methods</li>
</ul>
<h3 id="Non-convex-Optimization"><a href="#Non-convex-Optimization" class="headerlink" title="Non-convex Optimization"></a>Non-convex Optimization</h3><ul>
<li>Heuristic algorithms</li>
<li>Random search</li>
</ul>
<h3 id="Algorithms"><a href="#Algorithms" class="headerlink" title="Algorithms"></a>Algorithms</h3><ul>
<li>Bayes</li>
<li>KNN</li>
<li>K-means</li>
<li>Decision Tree</li>
<li>SVM</li>
<li>Boosting</li>
<li>Ensemble Learning</li>
<li>Linear Statistical Learning</li>
<li>Nonlinear Statistical Learning</li>
<li>Deep Neural Networks</li>
<li>Generative Adversarial Networks</li>
<li>Bayesian Networks</li>
<li>Reinforcement Learning</li>
<li>Federated Learning</li>
</ul>
<h2 id="Chapter-2-Preliminary"><a href="#Chapter-2-Preliminary" class="headerlink" title="Chapter 2 - Preliminary"></a>Chapter 2 - Preliminary</h2><h3 id="Curve-Fitting-and-Regularization"><a href="#Curve-Fitting-and-Regularization" class="headerlink" title="Curve Fitting and Regularization"></a>Curve Fitting and Regularization</h3><p><strong>Polynomial Curve Fitting</strong></p>
<script type="math/tex; mode=display">
y(x,\mathbf{w})=w_{0}+w_{1}x+w_{2}x+...+w_Mx^M=\sum^M_{i=0}w_ix^i</script><p><strong>Sum-of-Squares Error Function</strong></p>
<script type="math/tex; mode=display">
E(\mathbf w)=\frac 1 2 \sum\limits_{n=1}^N\{y(x_n,\mathbf w)-t_n\}^2</script><p><strong>Root-Mean-Square (RMS) Error</strong></p>
<script type="math/tex; mode=display">
E_{\text{RMS}}=\sqrt{2E(\mathbf w^\star)/N}</script><p>where $\mathbf w^\star=\mathop{\text{argmin}}\limits_{\bf w}\ E(\bf w)$.</p>
<p><strong>Regularization</strong></p>
<p>Discourage the coefficients from reaching large values.</p>
<script type="math/tex; mode=display">
\tilde E(\mathbf w)=\frac 1 2 \sum\limits_{n=1}^N\{y(x_n,\mathbf w)-t_n\}^2 + {\color{red}\frac{\lambda}2 \| \mathbf w \| ^2}</script><p>where $|{\bf w}|={\bf w}^T{\bf w}=w_0^2+w_1^2+\cdots+w_M^2$. </p>
<blockquote>
<p>Note that often the coefficient $w_0$ is omitted from the regularizer because its inclusion causes the results to depend on the choice of origin for the target variable (Hastie et al., 2001), or it may be included but with its own regularization coefficient</p>
</blockquote>
<h3 id="Probabilities-Theory"><a href="#Probabilities-Theory" class="headerlink" title="Probabilities Theory"></a>Probabilities Theory</h3><h4 id="Basic-Concepts"><a href="#Basic-Concepts" class="headerlink" title="Basic Concepts"></a>Basic Concepts</h4><ul>
<li><p>Marginal/Joint/Conditional Probability</p>
</li>
<li><p>Sum/Product Rule</p>
</li>
<li><p>Probability Densities</p>
</li>
<li><p>Bayes’ Theorem</p>
<script type="math/tex; mode=display">
p(Y\vert X)=\frac{p(X\vert Y)p(Y)}{p(X)}</script></li>
<li><p>Prior/Posterior Probability</p>
</li>
<li><p>Transformed Densities</p>
<script type="math/tex; mode=display">
\begin{align*}
p_y(y)&=p_x(x)|\frac{dx}{dy}|\\
&=p_x(g(y))|g\prime(y)|
\end{align*}</script></li>
<li><p>Expectations</p>
</li>
<li><p>Variances and Covariances</p>
</li>
</ul>
<h4 id="Gaussian-Distribution"><a href="#Gaussian-Distribution" class="headerlink" title="Gaussian Distribution"></a>Gaussian Distribution</h4><ul>
<li><p>The Gaussian Distribution</p>
<script type="math/tex; mode=display">
\mathcal N(x|\mu,\sigma^2)=\frac 1 {(2\pi\sigma^2)^{1/2}}\exp\left\{-\frac 1 {2\sigma^2}(x-\mu)^2\right\}</script></li>
<li><p>Gaussian Mean and Variance</p>
<script type="math/tex; mode=display">
\begin{align*}
\mathbb E[x]&=\int_{-\infty}^\infty \mathcal N(x\vert \mu,\sigma^2)x dx = \mu\\
\mathbb E[x^2]&=\int_{-\infty}^\infty \mathcal N(x\vert \mu,\sigma^2)x^2 dx = \mu^2 + \sigma^2\\
\text{var}[x]&=\mathbb E[x^2]-\mathbb E[x]^2 = \sigma^2
\end{align*}</script></li>
<li><p><a name="multigaussian">The Multivariate Gaussian</a></p>
<script type="math/tex; mode=display">
\mathcal N(\mathbf x|\mathbf\mu,\mathbf\Sigma)=\frac 1 {(2\pi)^{D/2}}\frac 1 {|\mathbf\Sigma|^{1/2}}\exp\left\{-\frac 1 2(\mathbf x-\mathbf\mu)^\text T\mathbf\Sigma^{-1}(\mathbf x - \mathbf \mu)\right\}</script></li>
</ul>
<h4 id="Likelihood-Function"><a href="#Likelihood-Function" class="headerlink" title="Likelihood Function"></a>Likelihood Function</h4><p>For a data set of independent observations $\mathbf x = (x_1,\cdots,x_N)^\text T$ of a Gaussian Distribution, its likelihood function is</p>
<script type="math/tex; mode=display">
p(\mathbf x \vert \mu,\sigma^2)=\prod\limits_{n=1}^N\mathcal N(x_n\vert\mu,\sigma^2)</script><p>Log Likelihood Function: </p>
<script type="math/tex; mode=display">
\ln p(\mathbf x|\mu,\sigma^2)=-\frac 1 {2\sigma^2}\sum\limits_{n=1}^N(x_n-\mu)^2 - \frac{N}2 \ln \sigma^2-\frac{N}2 \ln(2\pi)</script><p>By maximizing the log likelihood function, we have</p>
<script type="math/tex; mode=display">
\mu_{ML}=\frac 1 N \sum\limits_{n=1}^N x_n,\quad \sigma^2_{ML}=\frac 1 N  \sum\limits_{n=1}^N (x_n-\mu_{ML})^2</script><p>corresponding to the <strong>sample mean</strong> and the <strong>sample variance</strong>.</p>
<h4 id="Properties-of-mu-ML-and-sigma-2-ML"><a href="#Properties-of-mu-ML-and-sigma-2-ML" class="headerlink" title="Properties of $\mu_{ML}$ and $\sigma^2_{ML}$"></a>Properties of $\mu_{ML}$ and $\sigma^2_{ML}$</h4><p>The MLE will obtain the correct mean but will underestimate the true variance by a factor $\frac{N-1}{N}$ (bias).</p>
<script type="math/tex; mode=display">
\begin{align*}
\mathbb E[\mu_{ML}]&=\mu\\
\mathbb E[\sigma^2_{ML}]&=(\frac{N-1}N)\sigma^2\\
\widetilde \sigma^2&= (\frac N{N-1})\sigma^2_{ML}\\
&=\frac 1{N-1} \sum\limits_{n=1}^N (x_n-\mu_{ML})^2
\end{align*}</script><h4 id="Curve-fitting-re-visited"><a href="#Curve-fitting-re-visited" class="headerlink" title="Curve fitting re-visited"></a>Curve fitting re-visited</h4><p>Given $x$, the corresponding value of $t$ has a Gaussian distribution with a mean equal to the value $y(x, \mathbf w)$.</p>
<script type="math/tex; mode=display">
p(t\vert x,\mathbf w,\beta)=\mathcal N(t\vert y(x,\mathbf w),\beta^{-1})</script><p>where $\beta$ is the precision parameter corresponding to the inverse variance of the distribution: $\beta^{-1}=\sigma^2$.</p>
<p>Training data:</p>
<ul>
<li>Input values $\mathbf x=(x_1,\cdots,x_N)^\text T$</li>
<li>Target values $\mathbf t=(t_1,\cdots,t_N)^\text T$</li>
</ul>
<p><a name="likeli">Likelihood function</a>:</p>
<script type="math/tex; mode=display">
p(\mathbf t\vert \mathbf x,\mathbf w,\beta)=\prod\limits_{n=1}^N\mathcal N(t_n\vert y(x_n,\mathbf w),\beta^{-1})</script><p>Log likelihood function:</p>
<script type="math/tex; mode=display">
\ln p(\mathbf t\vert \mathbf x,\mathbf w,\beta)=-\frac\beta 2 \sum\limits_{n=1}^N\{y(x_n,\mathbf w)-t_n\}^2+\frac N 2 \ln \beta -\frac N 2 \ln(2\pi)</script><ul>
<li>The last two terms do not depend on $\bf w$, omitted.</li>
<li>Dividing a positive constant $\beta$ does not alter $\mathbf w_{ML}$, replace $\frac \beta 2$ with $\frac 1 2$.</li>
</ul>
<p>So <strong>maximizing the likelihood function</strong> is equivalent to <strong>minimizing the sum-of-squares error function</strong> $\sum\limits_{n=1}^N\{y(x_n,\mathbf w)-t_n\}^2$.</p>
<p>After obtaining $\mathbf w_{ML}$, we can further maximize the likelihood function w.r.t. $\beta$:</p>
<script type="math/tex; mode=display">
\frac 1 {\beta_{ML}}=\sum\limits_{n=1}^N\{y(x_n,\mathbf w_{ML})-t_n\}^2</script><p>Substitute $\mathbf w_{ML}$ and $\beta_{ML}$ back to get <a name="predictive_distribution"><strong>predictive distribution</strong></a>:</p>
<script type="math/tex; mode=display">
p(\mathbf t\vert \mathbf x,\mathbf w_{ML},\beta_{ML})=\prod\limits_{n=1}^N\mathcal N(t_n\vert y(x_n,\mathbf w_{ML}),\beta^{-1}_{ML})</script><h4 id="MAP-Maximum-Posteriori"><a href="#MAP-Maximum-Posteriori" class="headerlink" title="MAP: Maximum Posteriori"></a>MAP: Maximum Posteriori</h4><p><a name="prior">The prior distribution</a>:</p>
<script type="math/tex; mode=display">
p(\mathbf w\vert \alpha)=\mathcal N(\mathbf w|\mathbf 0,\alpha^{-1}\mathbf I)=(\frac\alpha{2\pi})^{(M+1)/2} \exp\{-\frac\alpha 2 \mathbf w^\text{T}\mathbf w\}</script><p>Review: <a href="#multigaussian">the Multivariate Gaussian</a>:</p>
<p>where $\alpha$ is the precision of the distribution(<em>hyperparameter</em>), and $M+1$ is the total number of elements in the vector $\bf w$ for an $M^\text{th}$ order polynomial.</p>
<p>Bayes’ Theorem: the posterior distribution for $\bf w$ is proportional to the product of the prior distribution and the likelihood function.</p>
<p><a name="posterior">The posterior distribution</a>:</p>
<script type="math/tex; mode=display">
\begin{align*}
&p(\mathbf w \vert\mathbf x,\mathbf t,\alpha,\beta)&\propto\quad&p(\mathbf t\vert \mathbf x,\mathbf w,\beta)&p(\mathbf w\vert\alpha)\\
&\text{posteriori}&\propto\quad&\text{likelihood}&\text{priori}
\end{align*}</script><p>Take the logarithm of the rhs, we already know the <a href="#likeli">likelihood function</a> and <a href="#prior">prior distribution</a> mentioned above, therefore maximizing posterior is to minimizing the following:</p>
<script type="math/tex; mode=display">
\frac\beta 2\sum\limits_{n=1}^N\{y(x_n,\mathbf w)-t_n\}^2+\frac\alpha 2 \mathbf w^\text{T}\mathbf w</script><p><strong>Maximizing the posterior distribution</strong> is equivalent to <strong>minimizing the regularized sum-of-squares error function</strong>, with regularization parameter $\lambda = \frac\alpha\beta$.</p>
<h4 id="Bayesian-Curve-Fitting"><a href="#Bayesian-Curve-Fitting" class="headerlink" title="Bayesian Curve Fitting"></a>Bayesian Curve Fitting</h4><p>Assume that the parameters $\alpha$ and $\beta$ are fixed and known in advance.</p>
<p>In Bayesian treatment, the predictive distribution can be written as:</p>
<script type="math/tex; mode=display">
p(t\vert x,\mathbf x, \mathbf t)=\int p(t\vert x,\mathbf w)p(\mathbf w\vert\mathbf x,\mathbf t)\text d\mathbf w</script><p>$p(t\vert x,\mathbf x, \mathbf t)$ is the <a href="#likeli">likelihood function</a> with omitted dependence on  $\alpha$ and $\beta$ .</p>
<p>$p(\mathbf w\vert\mathbf x,\mathbf t)$ is the <a href="#posterior">posterior distribution</a> which can be found by normalizing the rhs.</p>
<blockquote>
<p>For problems such as curve-fitting, this posterior distribution is a Gaussian and can be evaluated analytically. Similarly, the integration can also be performed analytically.</p>
</blockquote>
<p>The predictive distribution is given by a Gaussian of the form</p>
<script type="math/tex; mode=display">
p(t\vert x,\mathbf x,\mathbf t)=\mathcal N(t\vert m(x),s^2(x))</script><p>where the mean and variance are given by</p>
<script type="math/tex; mode=display">
\begin{align*}
m(x)&=\beta\phi(x)^\text T\textbf S\sum\limits_{n=1}^N \phi(x_n)t_n\\
s^2(x)&=\beta^{-1}+\phi(x)^\text T\textbf S\phi(x)
\end{align*}</script><p>Here the matrix $\textbf S$ is given by</p>
<script type="math/tex; mode=display">
\textbf S^{-1}=\alpha \textbf I + \beta\sum\limits_{n=1}^N\phi(x_n)\phi(x)^\text T</script><p>where $\textbf I$ is the unit matrix, the vector $\phi(x)$ with elements $\phi_i(x)=x^i$ for $i=0,\cdots,M$.</p>
<ul>
<li>The variance and the mean depend on $x$.</li>
<li>$\beta^{-1}$ represents the uncertainty in the predicted value of $t$, expressed in the <a href="#predictive_distribution">maximum likelihood predictive distribution</a> through $\beta^{-1}_{ML}$.</li>
<li>$\phi(x)^\text T\textbf S\phi(x)$ arises from the uncertainty in $\mathbf w$ and is a consequence of the Bayesian treatment.</li>
</ul>
<h3 id="Model-Selection"><a href="#Model-Selection" class="headerlink" title="Model Selection"></a>Model Selection</h3><p>S-fold Cross Validation</p>
<p><img src="https://s2.loli.net/2023/10/08/sa2LJItkVQEUCeS.png" alt="image.png" style="zoom: 50%;" /></p>
<p><em>leave-one-out</em>: $S=N$</p>
<h3 id="Curse-of-Dimensionality"><a href="#Curse-of-Dimensionality" class="headerlink" title="Curse of Dimensionality"></a>Curse of Dimensionality</h3><script type="math/tex; mode=display">
y(\mathbf x,\mathbf w)=w_0+\sum\limits_{i=1}^D w_ix_i+\sum\limits_{i=1}^D\sum\limits_{j=1}^Dw_{ij}x_ix_j+\sum\limits_{i=1}^D\sum\limits_{j=1}^D\sum\limits_{k=1}^Dw_{ijk}x_ix_jx_k+\cdots</script><p>For a polynomial of order $M$, the growth in the number of coefficients is $D^M$.</p>
<p>In spaces of high dimensionality, most of the volume of a sphere is concentrated in a thin shell near the surface, most of the probability mass of a Gaussian is located within a thin shell at a specific radius.</p>
<p><img src="https://s2.loli.net/2023/10/08/QfxjJAYzwHd8TVe.png" alt="image.png" style="zoom: 67%;" /></p>
<h3 id="Decision-Theory"><a href="#Decision-Theory" class="headerlink" title="Decision Theory"></a>Decision Theory</h3><h4 id="Confusion-Matrix"><a href="#Confusion-Matrix" class="headerlink" title="Confusion Matrix"></a>Confusion Matrix</h4><div class="table-container">
<table>
<thead>
<tr>
<th>Truth/Decision</th>
<th>Positive</th>
<th>Negative</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Positive</strong></td>
<td>TP</td>
<td>FN</td>
</tr>
<tr>
<td><strong>Negative</strong></td>
<td>FP</td>
<td>TN</td>
</tr>
</tbody>
</table>
</div>
<p><img src="https://s2.loli.net/2023/10/08/frI2BYLVbCgKNkc.png" alt="image.png" style="zoom:50%;" /></p>
<h4 id="Receiver-Operating-Characteristic-Curve"><a href="#Receiver-Operating-Characteristic-Curve" class="headerlink" title="Receiver Operating Characteristic Curve"></a>Receiver Operating Characteristic Curve</h4><p><img src="https://s2.loli.net/2023/10/08/Edem7OF3T8hXSaU.png" alt="image.png" style="zoom: 33%;" /></p>
<h4 id="Minimizing-the-misclassification-rate"><a href="#Minimizing-the-misclassification-rate" class="headerlink" title="Minimizing the misclassification rate"></a>Minimizing the misclassification rate</h4><p><img src="https://s2.loli.net/2023/10/08/YCeVcwDHuzB4i3k.png" alt="image.png"></p>
<script type="math/tex; mode=display">
\begin{align*}
p(\text{correct})&=\sum\limits_{k=1}^Kp(\mathbf x\in\mathcal R_k,\mathcal C_k) = \sum\limits_{k=1}^K\int_{\mathcal R_k} p(\mathbf x,\mathcal C_k)\text d \mathbf x\\
\end{align*}</script><h4 id="Minimizing-the-expected-loss"><a href="#Minimizing-the-expected-loss" class="headerlink" title="Minimizing the expected loss"></a>Minimizing the expected loss</h4><script type="math/tex; mode=display">
\mathbb E[L]=\sum\limits_k\sum\limits_j\int_{\mathcal R_j}L_{kj}p(\mathbf x,\mathcal C_k)\text d \mathbf x</script><p>Each $\mathbf x$ can be assigned  independently to one of the decision regions $\mathcal R_j$.</p>
<p>Goal is to choose $\mathcal R_j$ to minimize $\mathbb E[L]$, we should minimize $\sum\limits_{k} L_{kj}p(\mathbf x,\mathcal C_k)$ for each $\mathbf x$.</p>
<p>Common factor $p(\mathbf x)$ can be eliminated from $p(\mathbf x,\mathcal C_k)=p(\mathcal C_k\vert\mathbf x)p(\mathbf x)$.</p>
<p>Thus the decision rule that minimizes the expected loss is the one that assigns each new $\mathbf x$ to the class $j$ for which the quantity $\sum\limits_{k} L_{kj}p(\mathcal C_k\vert\mathbf x)$ is a minimum.</p>
<h4 id="Reject-Option"><a href="#Reject-Option" class="headerlink" title="Reject Option"></a>Reject Option</h4><p>Introducing a threshold $\theta$ and rejecting those inputs $x$ for which the largest of the posterior probabilities $p(\mathcal C_k\vert \mathbf x)$ is less than or equal to $\theta$. </p>
<ul>
<li>$\theta=1$: all examples are rejected.</li>
<li>$\theta&lt;\frac 1 K$: ($K$ classes) no examples are  rejected.</li>
</ul>
<p><img src="https://s2.loli.net/2023/10/08/yoqniUgpIN5b71F.png" alt="image.png" style="zoom:50%;" /></p>
<h4 id="Inference-and-Decision"><a href="#Inference-and-Decision" class="headerlink" title="Inference and Decision"></a>Inference and Decision</h4><p><strong>Generative model</strong>: Model the distribution of inputs as well as outputs. Because by sampling from them it is possible to generate synthetic data points in the input space.</p>
<p><strong>Discriminative model</strong>: model the posterior probabilities directly.</p>
<p><strong>Discriminant function</strong>: Learn a function that maps inputs x directly into decisions.</p>
<p><a name="3-ways-to-solve-decision-problems"><strong>3 Ways to Solve Decision Problems</strong></a></p>
<ul>
<li><p>(a)    By inference, determine $p(\mathbf x\vert \mathcal C_k)$ and $p(\mathcal C_k)$, then uses Bayes’ Theorem</p>
<script type="math/tex; mode=display">
p(\mathcal C_k\vert\mathbf x)=\frac{p(\mathbf x\vert\mathcal C_k)p(\mathcal C_k)}{p(\mathbf x)}=\frac{p(\mathbf x\vert\mathcal C_k)p(\mathcal C_k)}{\sum\limits_{k}p(\mathbf x\vert\mathcal C_k)p(\mathcal C_k)}=\frac{p(\mathbf x,\mathcal C_k)}{\sum\limits_{k}p(\mathbf x,\mathcal C_k)}</script><p>Equivalently, we can model the joint distribution $p(\mathbf x, \mathcal C_k)$ directly and then normalize to obtain the posterior probabilities.  (generative model)</p>
</li>
<li><p>(b)    By inference, determine the posterior class probabilities $p(\mathcal C_k\vert\mathbf x)$ directly. (discriminative model)</p>
</li>
<li>(c)    Find a function $f(x)$, called a <strong>discriminant function</strong>, which maps each input $\mathbf x$ directly onto a class label. <em>Probabilities play no role.</em></li>
</ul>
<details>
    <summary>Pros/Cons of the three approaches(extract from PRML)</summary>
    <p>Let us consider the relative merits of these three alternatives. Approach (a) is the most demanding because it involves finding the joint distribution over both <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="79" style="font-size: 122.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D431 TEX-B"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">x</mi></mrow></math></mjx-assistive-mml></mjx-container> and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="80" style="font-size: 122.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c43 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">C</mi></mrow><mi>k</mi></msub></math></mjx-assistive-mml></mjx-container>. For many applications, <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="81" style="font-size: 122.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D431 TEX-B"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">x</mi></mrow></math></mjx-assistive-mml></mjx-container> will have high dimensionality, and consequently we may need a large training set in order to be able to determine the class-conditional densities to reasonable accuracy. Note that the class priors <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="82" style="font-size: 122.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c43 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi><mo stretchy="false">(</mo><msub><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">C</mi></mrow><mi>k</mi></msub><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> can often be estimated simply from the fractions of the training set data points in each of the classes. One advantage of approach (a), however, is that it also allows the marginal density of data <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="83" style="font-size: 122.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D431 TEX-B"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi><mo stretchy="false">(</mo><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">x</mi></mrow><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> to be determined from <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="84" style="font-size: 122.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D431 TEX-B"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-munder space="4"><mjx-row><mjx-base><mjx-mo class="mjx-sop"><mjx-c class="mjx-c2211 TEX-S1"></mjx-c></mjx-mo></mjx-base></mjx-row><mjx-row><mjx-under style="padding-top: 0.167em; padding-left: 0.344em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-under></mjx-row></mjx-munder><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D431 TEX-B"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c7C"></mjx-c></mjx-mo><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c43 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c43 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi><mo stretchy="false">(</mo><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">x</mi></mrow><mo stretchy="false">)</mo><mo>=</mo><munder><mo data-mjx-texclass="OP" movablelimits="false">∑</mo><mrow data-mjx-texclass="ORD"><mi>k</mi></mrow></munder><mi>p</mi><mo stretchy="false">(</mo><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">x</mi></mrow><mo data-mjx-texclass="ORD" fence="false" stretchy="false">|</mo><msub><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">C</mi></mrow><mi>k</mi></msub><mo stretchy="false">)</mo><mi>p</mi><mo stretchy="false">(</mo><msub><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">C</mi></mrow><mi>k</mi></msub><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container>. This can be useful for detecting new data points that have low probability under the model and for which the predictions maybe of low accuracy, which is known as <em>outlier detection</em> or <em>novelty detection</em>.</p>
    <p>However, if we only wish to make classification decisions, then it can be wasteful of computational resources, and excessively demanding of data, to find the joint distribution <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="85" style="font-size: 122.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D431 TEX-B"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-msub space="2"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c43 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi><mo stretchy="false">(</mo><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">x</mi></mrow><mo>,</mo><msub><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">C</mi></mrow><mi>k</mi></msub><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> when in fact we only really need the posterior probabilities <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="86" style="font-size: 122.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c43 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c7C"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D431 TEX-B"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi><mo stretchy="false">(</mo><msub><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">C</mi></mrow><mi>k</mi></msub><mo data-mjx-texclass="ORD" fence="false" stretchy="false">|</mo><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">x</mi></mrow><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container>, which can be obtained directly through approach (b). Indeed, the class-conditional densities may contain a lot of structure that has little effect on the posterior probabilities, as illustrated in Figure 1.27. There has been much interest in exploring the relative merits of generative and discriminative approaches to machine learning, and in finding ways to combine them.</p>
    <p><img src="https://s2.loli.net/2023/10/08/sF7Khkg2mebAyVP.png" alt="image.png" style="zoom:50%;"></p>
    <p>An even simpler approach is (c) in which we use the training data to find a discriminant function <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="95" style="font-size: 122.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D453 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> that maps each <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="96" style="font-size: 122.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D431 TEX-B"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="bold">x</mi></math></mjx-assistive-mml></mjx-container> directly onto a class label, thereby combining the inference and decision stages into a single learning problem. In the example of Figure 1.27, this would correspond to finding the value of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="97" style="font-size: 122.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D431 TEX-B"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="bold">x</mi></math></mjx-assistive-mml></mjx-container> shown by the vertical green line, because this is the decision boundary giving the minimum probability of misclassification.</p>
    <p>With option (c), however, we no longer have access to the posterior probabilities <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="98" style="font-size: 122.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c43 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c7C"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D431 TEX-B"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi><mo stretchy="false">(</mo><msub><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">C</mi></mrow><mi>k</mi></msub><mo data-mjx-texclass="ORD" fence="false" stretchy="false">|</mo><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">x</mi></mrow><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container>. There are many powerful reasons for wanting to compute the posterior probabilities, even if we subsequently use them to make decisions. These include:</p>
    <ul>
<li>Minimizing risk.</li>
<li>Reject option. </li>
<li>Compensating for class priors.</li>
<li>Combining models. </li>
</ul>
</details>

<h4 id="Loss-functions-for-regression"><a href="#Loss-functions-for-regression" class="headerlink" title="Loss functions for regression"></a>Loss functions for regression</h4><p>For each input $\bf x$, choose a specific estimation $y(\bf x)$ of the value $t$.</p>
<script type="math/tex; mode=display">
\mathbb E[L]=\iint L(t,y(\mathbf x))p({\bf x},t)\text d {\bf x}\text dt</script><p>Take squared loss $L(t,y({\bf x}))=\{y({\bf x})-t\}^2$ for example</p>
<script type="math/tex; mode=display">
\mathbb E[L]=\iint \{y({\bf x})-t\}^2p({\bf x},t)\text d {\bf x}\text dt</script><h5 id="Method-1-Calculus-of-Variations"><a href="#Method-1-Calculus-of-Variations" class="headerlink" title="Method 1. Calculus of Variations"></a>Method 1. Calculus of Variations</h5><p>Using a calculus of variations to give $y({\bf x})$ so as to minimize $\mathbb E[L]$:</p>
<script type="math/tex; mode=display">
\frac{\partial \mathbb E[L]}{\partial y({\bf x})}=2\int \{y({\bf x})-t\}^2p({\bf x},t)\text d t =0</script><p>Solving for $y({\bf x})$, and using the sum and product rules of probability, we obtain the <a name="regression-function">regression function</a>:</p>
<script type="math/tex; mode=display">
y({\bf x})=\frac{\int tp({\bf x},t)\text d t}{p({\bf x})}=\int t p(t\vert \mathbf x)\text d t=\mathbb E_t[t\vert \mathbf x]</script><p>which is the conditional average of $t$ conditioned on $\bf x$.</p>
<h5 id="Method-2-Expanding-the-square-term"><a href="#Method-2-Expanding-the-square-term" class="headerlink" title="Method 2. Expanding the square term"></a>Method 2. Expanding the square term</h5><script type="math/tex; mode=display">
\begin{align*}
\{y({\bf x})-t\}^2&=\{y({\bf x})-\mathbb E_t[t\vert\mathbf x]+\mathbb E_t[t\vert\mathbf x]-t\}^2\\
&=\{y({\bf x})-\mathbb E_t[t\vert\mathbf x]\}^2+2\{y({\bf x})-\mathbb E_t[t\vert\mathbf x]\}\{\mathbb E_t[t\vert\mathbf x]-t\}+\{\mathbb E_t[t\vert\mathbf x]-t\}^2
\end{align*}</script><p>Substitute into the loss function and perform the integral on $t$:</p>
<script type="math/tex; mode=display">
\mathbb E[L]=\int\{y({\bf x})-\mathbb E_t[t\vert\mathbf x]\}^2p(\mathbf x)\text d \mathbf x+\int\{\mathbb E_t[t\vert\mathbf x]-t\}^2p(\mathbf x)\text d\mathbf x</script><p>When $y({\bf x})=\mathbb E_t[t\vert \mathbf x]$, loss function $\mathbb E[L]$ is minimized.</p>
<p>The second term represents the intrinsic variability of the target data and can be regarded as <strong>noise</strong>, or minimum value of the loss function.</p>
<p><strong>3 Ways to Solve Regression Problems</strong> (in order of decreasing complexity)</p>
<ul>
<li>(a)    Inference to determine the joint density $p({\bf x},t)$, then normalize to find the conditional density $p(t\vert \mathbf x)$, finally marginalize to find the conditional mean by the <a href="#regression-function">regression function</a>.</li>
<li>(b)    Inference to determine the conditional density $p(t\vert \mathbf x)$,  then marginalize to find the conditional mean by the <a href="#regression-function">regression function</a>.</li>
<li>(c)    Find a regression function $y(\mathbf x)$ directly from the training data.</li>
</ul>
<p>The relative merits of these three approaches follow the same lines as for <a href="#3-ways-to-solve-decision-problems">classification problems</a>.</p>
<details>
    <summary>Minkowski loss</summary>
<script type="math/tex; mode=display">
\mathbb E[L_q]=\iint \vert y(\mathbf x)-t\vert^q p(\mathbf x,t)\text d \mathbf x\text d t</script><p><img src="https://s2.loli.net/2023/10/08/sq5Oz4LW1bVXuvG.png" alt="image.png" style="zoom: 33%;" /></p>
<p>The minimum of $\mathbb E[L_q]$ is given by:</p>
<ul>
<li>$q\rightarrow 0$: conditional mode</li>
<li>$q=1$: conditional median</li>
<li>$q=2$: conditional mean</li>
</ul>
</details>

<h3 id="Information-Theory"><a href="#Information-Theory" class="headerlink" title="Information Theory"></a>Information Theory</h3><h4 id="Entropy-statistical"><a href="#Entropy-statistical" class="headerlink" title="Entropy(statistical)"></a>Entropy(statistical)</h4><h5 id="Discrete"><a href="#Discrete" class="headerlink" title="Discrete"></a>Discrete</h5><p>Allocate $N$ identical objects in $M$ bins.</p>
<script type="math/tex; mode=display">
W=\frac{N!}{\prod\limits_in_i!}</script><script type="math/tex; mode=display">
\text H=\frac 1 N \ln W\simeq -\lim\limits_{N\rightarrow\infty}\sum\limits_{i}(\frac{n_i}N)\ln(\frac{n_i}N)=-\sum\limits_{i}p_i\ln p_i</script><p>Entropy maximized when $\forall i,\ p_i=\frac 1 M$.</p>
<p><strong>Continuous</strong></p>
<p>Put bins of width $\Delta$ along the real line.</p>
<script type="math/tex; mode=display">
\lim\limits_{\Delta\rightarrow0}\left\{-\sum\limits_{i}p(x_i)\Delta\ln p(x_i)\right\}=-\int p(x)\ln p(x)\text d x</script><p>For fixed $\sigma^2$, when $p(x)=\mathcal N(x\vert\mu,\sigma^2)$, differential entropy is maximized</p>
<script type="math/tex; mode=display">
\text H[x]=\frac 1 2\{1+\ln(2\pi\sigma^2)\}</script><h4 id="Entropy"><a href="#Entropy" class="headerlink" title="Entropy"></a>Entropy</h4><script type="math/tex; mode=display">
\begin{align*}
\text H[x]&=-\sum\limits_x p(x)\ln p(x)\\
\text H[x]&=-\int p(x)\ln p(x)\text d x
\end{align*}</script><h4 id="Conditional-Entropy"><a href="#Conditional-Entropy" class="headerlink" title="Conditional Entropy"></a>Conditional Entropy</h4><script type="math/tex; mode=display">
\text H[y\vert x]=-\iint p(\mathbf y,\mathbf x)\ln p(\mathbf y\vert\mathbf x)\text d\mathbf y\text d\mathbf x</script><script type="math/tex; mode=display">
\text H[\mathbf x,\mathbf y]=\text H[\mathbf y\vert\mathbf x]+\text H[\mathbf x]</script><h4 id="Relative-Entropy-The-Kullback-Leibler-Divergence"><a href="#Relative-Entropy-The-Kullback-Leibler-Divergence" class="headerlink" title="Relative Entropy (The Kullback-Leibler Divergence)"></a>Relative Entropy (The Kullback-Leibler Divergence)</h4><p>KL divergence describes a distance between model $p$ and model $q$.</p>
<script type="math/tex; mode=display">
\begin{align*}
\text{KL}(p\|q)&=\text{Cross Entropy C}(p\|q)-\text {Entropy H}(p)\\
&=-\int p(\mathbf x)\ln q(\mathbf x)\text d\mathbf x-\left(-\int p(\mathbf x)\ln p(\mathbf x)\text d\mathbf x\right)\\
&=-\int p(\mathbf x)\ln \left\{\frac{q(\mathbf x)}{p(\mathbf x)}\right\}\text d\mathbf x
\end{align*}</script><ol>
<li>It is not a symmetrical quantity: $\text{KL}(p|q)\not\equiv \text{KL}(q|p)$.</li>
<li>$\text {KL}(p|q)\ge 0$, with equality IFF $p(\mathbf x)=q(\mathbf x)$.</li>
</ol>
<p>Approximate distribution $p(\mathbf x)$ using distribution $q(\mathbf x\vert\boldsymbolθ)$  governed by a set of adjustable parameters $\boldsymbol\theta$. One way to determine $\boldsymbol\theta$ is to minimize the KL divergence between the two distributions.</p>
<script type="math/tex; mode=display">
\text{KL}(p\|q)\simeq \frac 1 N \sum\limits_{n=1}^N\{\ln q(\mathbf x_n\vert\boldsymbol\theta)+\ln p(\mathbf x_n)\}</script><p>The 1st term is the negative log likelihood function for $\boldsymbol\theta$. The 2nd term is independent of $\boldsymbol\theta$. So minimizing this KL divergence is equivalent to maximizing the likelihood function.</p>
<h4 id="Cross-Entropy-for-Machine-Learning"><a href="#Cross-Entropy-for-Machine-Learning" class="headerlink" title="Cross Entropy for Machine Learning"></a>Cross Entropy for Machine Learning</h4><ul>
<li>Goal of ML: $p(\text{real data})\approx p(\text{model}\vert\theta)$</li>
<li>We assume: $p(\text{training data})\approx p(\text{real data})$</li>
<li>Operation of ML: $p(\text{training data})\approx p(\text{model}\vert\theta)$</li>
</ul>
<p>Minimizing $\text{KL}(p(\text{training data})|p(\text{model}\vert\theta))$ is equivalent to minimizing $\text C(p(\text{training data})|p(\text{model}\vert\theta))$ as $\text H(p(\text{training data}))$ is fixed.</p>
<p><strong>Example. Bernoulli model</strong></p>
<script type="math/tex; mode=display">
p(\text{model}\vert\theta)=\rho^t(1-\rho)^{1-t}</script><script type="math/tex; mode=display">
\text C=-\frac 1 N \sum\limits_nt_n\ln\rho+(1-t_n)\ln(1-\rho)</script><p>where $t_n$ is the training data and $\rho$ is the model parameter.</p>
<p><strong>Example. Gaussian model</strong></p>
<script type="math/tex; mode=display">
p(\text{model}\vert\theta)\propto e^{-\frac{(t-\mu)^2}{2}}</script><script type="math/tex; mode=display">
\text C\propto \frac 1 N \sum\limits_n(t_n-\mu)^2</script><p>where $t_n$ is the training data and $\mu$ is the model parameter.</p>
<h4 id="Mutual-Information"><a href="#Mutual-Information" class="headerlink" title="Mutual Information"></a>Mutual Information</h4><p>Mutual information describes the degree of dependence between $\mathbf x$ and $\mathbf y$ </p>
<script type="math/tex; mode=display">
\begin{align*}
\text I[\mathbf x,\mathbf y]&\equiv\text{KL}(p(\mathbf x,\mathbf y)\|p(\mathbf x)p(\mathbf y))\\
&=-\iint p(\mathbf x,\mathbf y)\ln\left(\frac{p(\mathbf x)p(\mathbf y)}{p(\mathbf x,\mathbf y)}\right)\text d\mathbf x\text d\mathbf y
\end{align*}</script><script type="math/tex; mode=display">
\text I[\mathbf x,\mathbf y]=\text H[\mathbf x]-\text H[\mathbf x\vert\mathbf y]=\text H[\mathbf y]-\text H[\mathbf y\vert\mathbf x]</script><h4 id="Information-Gain"><a href="#Information-Gain" class="headerlink" title="Information Gain"></a>Information Gain</h4><p>Given $N$ balls and a balance, one of these balls is lighter.</p>
<p>$x$: one ball is lighter</p>
<p>$y$: weighing once</p>
<p>$\text H[x]$: uncertain of balls</p>
<p>$\text H[x\vert y]$: uncertain of balls after weighing once</p>
<script type="math/tex; mode=display">
\begin{align*}
\text H[x\vert y_1,\cdots,y_t]-\text H[x\vert y_1,\cdots,y_{t+1}]&=\text H[y_{t+1}\vert y_1,\cdots,y_t]-H[y_{t+1}\vert y_1,\cdots,y_t,x]\\
&=\text H[y_{t+1}\vert y_1,\cdots,y_t]\\
&\le \text H[y_{t+1}]=\log_23
\end{align*}</script><p>Sum the equation above with $t=0,1,\cdots,T$, </p>
<script type="math/tex; mode=display">
\begin{matrix*}
\log_2N = \text H[x]-\text H[x\vert y_1,\cdots,y_T]\le T\log_23\\
T\ge \log_3N
\end{matrix*}</script><h2 id="Chapter-3-Distributions"><a href="#Chapter-3-Distributions" class="headerlink" title="Chapter 3 - Distributions"></a>Chapter 3 - Distributions</h2><h3 id="Binary-Distributions"><a href="#Binary-Distributions" class="headerlink" title="Binary Distributions"></a>Binary Distributions</h3><h4 id="Bernoulli-Distribution"><a href="#Bernoulli-Distribution" class="headerlink" title="Bernoulli Distribution"></a>Bernoulli Distribution</h4><script type="math/tex; mode=display">
\begin{align*}
\text{Bern}(x\vert \mu)&=\mu^x(1-\mu)^{1-x}\\
\mathbb E[x]&=\mu\\
\text{var}[x]&=\mu(1-\mu)
\end{align*}</script><p>Given $\mathcal D=\{x_1,\cdots,x_N\}$, $m$ heads, $N-m$ tails.</p>
<script type="math/tex; mode=display">
\ln p(\mathcal D\vert\mu)=\sum\limits_{n=1}^N\ln p(x_n\vert\mu)=\sum\limits_{n=1}^N\{x_n\ln\mu+(1-x_n\ln(1-\mu)\}</script><script type="math/tex; mode=display">
\mu_\text{ML}=\frac 1 N\sum\limits_{n=1}^Nx_n=\frac m N</script><h4 id="Binomial-Distribution"><a href="#Binomial-Distribution" class="headerlink" title="Binomial Distribution"></a>Binomial Distribution</h4><script type="math/tex; mode=display">
\begin{align*}
\text{Bin}(m\vert N,\mu)&=\left(\begin{matrix}N\\m\end{matrix}\right)\mu^m(1-\mu)^{N-m}\\
\mathbb E[m]&=\sum\limits_{m=0}^Nm\text{Bin}(m\vert N,\mu)=N\mu\\
\text{var}[m]&=\sum\limits_{m=0}^N(m-\mathbb E[m])^2\text{Bin}(m\vert N,\mu)=N\mu(1-\mu)
\end{align*}</script><h4 id="Beta-Distribution"><a href="#Beta-Distribution" class="headerlink" title="Beta Distribution"></a><a target="_blank" rel="noopener" href="http://varianceexplained.org/statistics/beta_distribution_and_baseball/">Beta Distribution</a></h4><script type="math/tex; mode=display">
\begin{align*}
\Gamma(x)&\equiv\int_0^\infty u^{x-1}e^{-u}du\\
\text{Beta}(\mu\vert a,b)&=\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\mu^{a-1}(1-\mu)^{b-1}\\
\mathbb E[\mu]&=\frac a {a+b}\\
\text{var}[\mu]&=\frac{ab}{(a+b)^2(a+b+1)}
\end{align*}</script><p>The Beta distribution provides the <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Conjugate_prior"><strong>conjugate prior</strong></a> for the Bernoulli distribution.</p>
<p>Given $\mathcal D=\{x_1,\cdots,x_N\}$, $m$ heads, $N-m$ tails.</p>
<script type="math/tex; mode=display">
\begin{matrix}
p(\mu\vert a_0,b_0,\mathcal D)\propto p(\mathcal D\vert\mu)p(\mu\vert a_0,b_0)\propto \text{Beta}(\mu\vert a_N,b_N)\\
a_N=a_0+m\quad\quad b_N=b_0+(N-m)
\end{matrix}</script><p>As the size of the dataset $N$ increases,</p>
<script type="math/tex; mode=display">
\begin{align*}
a_N &\rightarrow m\\
b_N &\rightarrow N-m\\
\mathbb E[\mu]&\rightarrow \mu_\text{ML}\\
\text{var}[\mu]&\rightarrow 0
\end{align*}</script><h3 id="Multinomial-Distributions"><a href="#Multinomial-Distributions" class="headerlink" title="Multinomial Distributions"></a>Multinomial Distributions</h3><h4 id="1-of-K-coding-scheme"><a href="#1-of-K-coding-scheme" class="headerlink" title="1-of-K coding scheme"></a>1-of-K coding scheme</h4><p>1-of-K coding scheme: $\mathbf x=(0,0,1,0,0,0)^\text T,\ \sum\limits_{k=1}^Kx_k=1$.</p>
<script type="math/tex; mode=display">
p(\text x\vert\boldsymbol\mu)=\prod\limits_{k=1}^K\mu_k^{x_k}</script><p>where $\boldsymbol\mu=(\mu_1,\cdots,\mu_K)^\text T$, $\sum\limits_k\mu_k=1$.</p>
<script type="math/tex; mode=display">
\mathbb E[\mathbf x\vert\boldsymbol \mu]=\sum\limits_{\mathbf x}p(\mathbf x\vert\boldsymbol\mu)\mathbf x=(\mu_1,\cdots,\mu_K)^\text T=\boldsymbol \mu</script><p>Given $\mathcal D=\{\bf x_1,\cdots,x_N\}$, the likelihood</p>
<script type="math/tex; mode=display">
p(\mathcal D\vert\mu)=\prod\limits_{n=1}^N\prod\limits_{k=1}^K\mu_k^{x_{nk}}=\prod_{k=1}^K\mu_k^{\left(\sum\limits_{n=1}^Nx_{nk}\right)}=\prod_{k=1}^K\mu_k^{m_k}</script><p>where $ m_k=\sum\limits_{n=1}^Nx_{nk}$ denotes the number of observations of $x_k = 1$.</p>
<p>Using Lagrange method, we obtain</p>
<script type="math/tex; mode=display">
\mu^\text{ML}_k=\frac {m_k} N</script><h4 id="Multinomial-Distribution"><a href="#Multinomial-Distribution" class="headerlink" title="Multinomial Distribution"></a>Multinomial Distribution</h4><script type="math/tex; mode=display">
\begin{align*}
\text{Mult}(m_1,\cdots,m_K\vert\boldsymbol\mu,N)&=\left(\begin{matrix}N\\m_1\cdots m_K\end{matrix}\right)\prod\limits_{k=1}^K\mu_k^{m_k}\\
\mathbb E[m_k]&=N\mu_k\\
\text{var}[m_k]&=N\mu_k(1-\mu_k)\\
\text{cov}[m_jm_k]&=-N\mu_j\mu_k
\end{align*}</script><h4 id="Dirichlet-Distribution"><a href="#Dirichlet-Distribution" class="headerlink" title="Dirichlet Distribution"></a>Dirichlet Distribution</h4><p>Conjugate prior for the multinomial distribution.</p>
<script type="math/tex; mode=display">
\begin{matrix}
\text{Dir}(\boldsymbol\mu\vert\boldsymbol\alpha)=\frac{\Gamma(\alpha_0)}{\Gamma(\alpha_1)\cdots\Gamma(\alpha_K)}\prod\limits_{k=1}^K\mu_k^{\alpha_k-1}\\
\alpha_0=\sum\limits_{k=1}^K\alpha_k
\end{matrix}</script><p>Given $\mathcal D=\{m_1,\cdots,m_K\}$, the likelihood</p>
<script type="math/tex; mode=display">
\begin{matrix}
p(\boldsymbol\mu\vert\mathcal D,\boldsymbol\alpha)\propto p(\mathcal D\vert\boldsymbol\mu)p(\boldsymbol\mu\vert\boldsymbol\alpha)\propto\prod\limits_{k=1}^K\mu_k^{\alpha_k+m_k-1}\\
p(\boldsymbol\mu\vert\mathcal D,\boldsymbol\alpha)=\text{Dir}(\boldsymbol\mu\vert\boldsymbol\alpha+\bf m)
\end{matrix}</script><p>where $\mathbf m=(m_1,\cdots,m_K)^\text T$.</p>
<p>We can interpret the parameters $\alpha_k$ of the Dirichlet prior as an effective number of observations of $x_k = 1$.</p>
<h3 id="Gaussian-Distributions"><a href="#Gaussian-Distributions" class="headerlink" title="Gaussian Distributions"></a>Gaussian Distributions</h3><ul>
<li><p>The Gaussian Distribution</p>
<script type="math/tex; mode=display">
\mathcal N(x|\mu,\sigma^2)=\frac 1 {(2\pi\sigma^2)^{1/2}}\exp\left\{-\frac 1 {2\sigma^2}(x-\mu)^2\right\}</script></li>
<li><p>The Multivariate Gaussian</p>
<script type="math/tex; mode=display">
\mathcal N(\mathbf x|\mathbf\mu,\mathbf\Sigma)=\frac 1 {(2\pi)^{D/2}}\frac 1 {|\mathbf\Sigma|^{1/2}}\exp\left\{-\frac 1 2(\mathbf x-\mathbf\mu)^\text T\mathbf\Sigma^{-1}(\mathbf x - \mathbf \mu)\right\}</script></li>
</ul>
<h4 id="Central-Limit-Theorem"><a href="#Central-Limit-Theorem" class="headerlink" title="Central Limit Theorem"></a>Central Limit Theorem</h4><p>The distribution of the sum of $N$ i.i.d. random variables becomes increasingly Gaussian as $N$ grows.</p>
<h4 id="Moments-of-the-Multivariate-Gaussian"><a href="#Moments-of-the-Multivariate-Gaussian" class="headerlink" title="Moments of the Multivariate Gaussian"></a>Moments of the Multivariate Gaussian</h4><script type="math/tex; mode=display">
\begin{align*}
\mathbb E[\mathbf x]&=\boldsymbol\mu\\
\mathbb E[\mathbf x\mathbf x^\text T]&=\boldsymbol\mu\boldsymbol\mu^\text T+\boldsymbol\Sigma\\
\text{cov}[\mathbf x]&=\boldsymbol\Sigma\\
\text{cov}[A\mathbf x]&=A\boldsymbol\Sigma A^\text T
\end{align*}</script><h4 id="Properties-of-Gaussians"><a href="#Properties-of-Gaussians" class="headerlink" title="Properties of Gaussians"></a>Properties of Gaussians</h4><ol>
<li>Linear transformation</li>
</ol>
<script type="math/tex; mode=display">
\begin{align*}
X&\sim\mathcal N(\mu,\sigma^2)\\
Y&=aX+b\\
Y&\sim\mathcal N(a\mu+b,a^2\sigma^2)
\end{align*}</script><ol>
<li><p>Product of Gaussian r.v.</p>
<script type="math/tex; mode=display">
\begin{align*}X_1&\sim\mathcal N(\mu_1,\sigma_1^2)\\X_2&\sim\mathcal N(\mu_2,\sigma_2^2)\\\
p(Y)&=p(X_1)p(X_2)\\
Y&\sim\mathcal N(\frac{\sigma^2_2}{\sigma_1^2+\sigma_2^2}\mu_1+\frac{\sigma^2_1}{\sigma_1^2+\sigma_2^2}\mu_2,\frac 1 {\sigma_1^{-2}+\sigma_2^{-2}})
\end{align*}</script><script type="math/tex; mode=display">
\left\{\begin{align*}\sigma^{-2}&=\sigma_1^{-2}+\sigma_2^{-2}\\\sigma^{-2}\mu&=\sigma_1^{-2}\mu_1+\sigma_2^{-2}\mu_2\end{align*}\right .</script><p>For multivariate Gaussians, use $\Sigma$ to replace $\sigma^2$.</p>
</li>
</ol>
<h4 id="Bayes’-Theorem-for-Gaussian-Variables-Slides"><a href="#Bayes’-Theorem-for-Gaussian-Variables-Slides" class="headerlink" title="Bayes’ Theorem for Gaussian Variables(Slides)"></a>Bayes’ Theorem for Gaussian Variables(Slides)</h4><p>Given $y=Ax+v$, $p(x)=\mathcal N(x\vert\mu,\Sigma)$, $p(v)=\mathcal N(v\vert,0,Q)$.</p>
<p>Hence we have</p>
<script type="math/tex; mode=display">
\begin{align*}
p(y)&=\mathcal N(y\vert A\mu,A\Sigma A^\text T+Q)\\
p(y\vert x)&=\mathcal N(y\vert Ax,Q)
\end{align*}</script><p>Therefore</p>
<script type="math/tex; mode=display">
\begin{align*}
p(x\vert y)&\propto p(y\vert x)p(x)=\mathcal N(y\vert Ax,Q)\mathcal N(x\vert \mu,\Sigma)\\
p(x\vert y) &= \mathcal N(x\vert Hy,L)\\
\end{align*}</script><p>where</p>
<script type="math/tex; mode=display">
\left\{ \begin{align*}
L^{-1}&=A^TQ^{-1}A + \Sigma^{-1}\\
Hy &= L\{A^TQ^{-1}y+\Sigma^{-1}\mu\}
\end{align*}\right.</script><h4 id="Conditional-Gaussian-distributions"><a href="#Conditional-Gaussian-distributions" class="headerlink" title="Conditional Gaussian distributions"></a>Conditional Gaussian distributions</h4><p>If two sets of variables are jointly Gaussian, then the conditional distribution of one set conditioned on the other is again Gaussian.</p>
<p>Given a $D$-dimensional vector $\mathbf x$ with Gaussian distribution $\mathcal N(\mathbf x\vert\boldsymbol\mu,\boldsymbol\Sigma)$, partitioned into two disjoint subsets $\mathbf x_a$ and $\mathbf x_b$.</p>
<script type="math/tex; mode=display">
\mathbf x=\left(\begin{matrix}\mathbf x_a\\\mathbf x_b\end{matrix}\right)\quad\boldsymbol\mu=\left(\begin{matrix}\boldsymbol \mu_a\\\boldsymbol \mu_b\end{matrix}\right)\quad\boldsymbol\Sigma=\begin{pmatrix}\boldsymbol\Sigma_{aa}&\boldsymbol\Sigma_{ab}\\\boldsymbol\Sigma_{ba}&\boldsymbol\Sigma_{bb}\end{pmatrix}</script><p>For conditional distribution $p(\mathbf x_a\vert\mathbf x_b)$,</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\mathbf x_a\vert\mathbf x_b)&=\mathcal N(x_a\vert\boldsymbol\mu_{a\vert b},\boldsymbol\Sigma_{a\vert b})\\
\boldsymbol\mu_{a\vert b}&=\boldsymbol\mu_a+\boldsymbol\Sigma_{ab}\boldsymbol\Sigma_{bb}^{-1}(\mathbf x_b-\boldsymbol\mu_b)\\
\boldsymbol\Sigma_{a\vert b}&=\boldsymbol\Sigma_{aa}-\boldsymbol\Sigma_{ab}\boldsymbol\Sigma_{bb}^{-1}\boldsymbol\Sigma_{ba}
\end{align*}</script><p>And marginal distribution $p(\mathbf x_a)=\mathcal N(\mathbf x_a\vert\boldsymbol\mu_a,\boldsymbol\Sigma_{aa})$.</p>
<h4 id="Bayes’-Theorem-for-Gaussian-Variables-Textbook"><a href="#Bayes’-Theorem-for-Gaussian-Variables-Textbook" class="headerlink" title="Bayes’ Theorem for Gaussian Variables(Textbook)"></a>Bayes’ Theorem for Gaussian Variables(Textbook)</h4><p>Given</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\mathbf x)&=\mathcal N(\mathbf x\vert\boldsymbol\mu,\boldsymbol\Lambda^{-1})\\
p(\mathbf y\vert \mathbf x)&=\mathcal N(\bf y\vert Ax+b, L^{-1})
\end{align*}</script><p>Obtain</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\mathbf y)&=\mathcal N(\bf y\vert A\mu+b,L^{-1}+A\Lambda^{-1}A^\text T)\\
p(\mathbf x\vert\mathbf y)&=\mathcal N(\bf x\vert\boldsymbol \Sigma\{A^\text TL(y-b)+\Lambda\boldsymbol\mu\},\Sigma)
\end{align*}</script><p>where</p>
<script type="math/tex; mode=display">
\boldsymbol\Sigma=(\bf\Lambda+A^\text{T}LA)^{-1}.</script><h4 id="Maximum-Likelihood-for-the-Gaussian"><a href="#Maximum-Likelihood-for-the-Gaussian" class="headerlink" title="Maximum Likelihood for the Gaussian"></a>Maximum Likelihood for the Gaussian</h4><p>Sufficient statistics: $\sum\limits_{n=1}^N\mathbf x_n$ and $\sum\limits_{n=1}^N\mathbf x_n\mathbf x_n^\text T$</p>
<p>Solve the maximum likelihood</p>
<script type="math/tex; mode=display">
\boldsymbol\mu_\text{ML}=\frac 1 N\sum\limits_{n=1}^N\mathbf x_n\quad \boldsymbol\Sigma_\text{ML}=\frac 1 N\sum\limits_{n=1}^N(\mathbf x_n-\boldsymbol\mu_\text{ML})(\mathbf x_n-\boldsymbol\mu_\text{ML})^\text T.</script><p>Under the true distribution</p>
<script type="math/tex; mode=display">
\mathbb E[\boldsymbol \mu_\text{ML}]=\boldsymbol\mu\quad\mathbb E[\boldsymbol \Sigma_\text{ML}]=\frac{N-1}N\boldsymbol\Sigma.</script><p>Hence define</p>
<script type="math/tex; mode=display">
\widetilde{\boldsymbol\Sigma}=\frac 1 {N-1}\sum\limits_{n=1}^N(\mathbf x_n-\boldsymbol\mu_\text{ML})(\mathbf x_n-\boldsymbol\mu_\text{ML})^\text T.</script><h4 id="Sequential-estimation"><a href="#Sequential-estimation" class="headerlink" title="Sequential estimation"></a>Sequential estimation</h4><p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Stochastic_approximation#Robbins%E2%80%93Monro_algorithm">The Robbins-Monro Algorithm</a></p>
<h4 id="Bayesian-Inference-for-the-Gaussian"><a href="#Bayesian-Inference-for-the-Gaussian" class="headerlink" title="Bayesian Inference for the Gaussian"></a>Bayesian Inference for the Gaussian</h4><h4 id="Student’s-t-distribution"><a href="#Student’s-t-distribution" class="headerlink" title="Student’s t-distribution"></a><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Student%27s_t-distribution">Student’s t-distribution</a></h4><h4 id="Periodic-variables"><a href="#Periodic-variables" class="headerlink" title="Periodic variables"></a>Periodic variables</h4><h4 id="Mixtures-of-Gaussians"><a href="#Mixtures-of-Gaussians" class="headerlink" title="Mixtures of Gaussians"></a>Mixtures of Gaussians</h4><script type="math/tex; mode=display">
p(\mathbf x)=\sum\limits_{k=1}^K\pi_k\mathcal N(\mathbf x\vert\boldsymbol\mu_k,\boldsymbol\Sigma_k)</script><ul>
<li><p>$\pi_k$: mixing coefficients</p>
<p> $\sum\limits_{k=1}^K\pi_k=1,0\le\pi_k\le 1$</p>
</li>
<li><p>$N(\mathbf x\vert\boldsymbol\mu_k,\boldsymbol\Sigma_k)$: component</p>
</li>
</ul>
<p>Log likelihood of mixtures</p>
<script type="math/tex; mode=display">
\ln p(\mathbf X\vert\boldsymbol \pi,\boldsymbol\mu,\boldsymbol\Sigma)=\sum\limits_{n=1}^N\ln\left\{\sum\limits_{k=1}^K\pi_k\mathcal N(\mathbf x\vert\boldsymbol\mu_k,\boldsymbol\Sigma_k)\right\}</script><p>The maximum likelihood solution for the parameters no longer has a closed-form analytical solution.</p>
<p>Alternatives: iterative numerical optimization, expectation maximization.</p>
<h3 id="Exponential-Families"><a href="#Exponential-Families" class="headerlink" title="Exponential Families"></a>Exponential Families</h3><p>The exponential family of distributions over $\mathbf x$, given parameters $\boldsymbol \eta$</p>
<script type="math/tex; mode=display">
p(\mathbf x\vert\boldsymbol\eta)=h(\mathbf x)g(\boldsymbol\eta)\exp\{\boldsymbol\eta^\text T\mathbf u(\mathbf x)\}</script><ul>
<li>$\bf x$: scalar or vector, discrete or continuous.</li>
<li>$\boldsymbol\eta$: natural parameters</li>
<li>$g(\boldsymbol\eta)$: normalization coefficient satisfying ↓</li>
</ul>
<script type="math/tex; mode=display">
g(\boldsymbol\eta)\int h(\mathbf x)\exp\left\{\boldsymbol\eta^\text T \mathbf u(\mathbf x)\right\}\text d\mathbf x=1</script><p><strong>The Bernoulli Distribution</strong>: </p>
<script type="math/tex; mode=display">
p(x\vert \mu)=(1-\mu)\exp\left\{\ln(\frac{\mu}{1-\mu})x\right\}</script><p>So</p>
<script type="math/tex; mode=display">
\begin{align*}
\eta = \ln(\frac \mu{1-\mu}), \mu=&\sigma(\eta)=\frac 1{1+\exp(-\eta)}\\
&\uparrow\text{Logistic Sigmoid}
\end{align*}</script><p><strong>The Multinomial Distribution:</strong></p>
<script type="math/tex; mode=display">
p(\mathbf x\vert\boldsymbol \mu)=\exp\left\{\sum\limits_{k=1}^Mx_k\ln\mu_k\right\}</script><p>Let $\mu_M=1-\sum\limits_{k=1}^{M-1}\mu_k$,</p>
<script type="math/tex; mode=display">
\begin{align*}
\eta_k=\ln\left(\frac {\mu_k} {1-\sum_{j=1}^{M-1}\mu_j}\right), \mu_k = &\frac{\exp(\eta_k)}{1+\sum_{j=1}^{M-1}\exp(\eta_j)}\\
&\uparrow\text{Softmax}
\end{align*}</script><p><strong>The Gaussian Distribution:</strong></p>
<script type="math/tex; mode=display">
p(x\vert\mu,\sigma^2)=\frac 1 {\sqrt{2\pi\sigma^2}}\exp\left\{-\frac 1 {2\sigma^2}(x-\mu)^2\right\}=h(x)g(\boldsymbol\eta)\exp\left\{\boldsymbol\eta^\text T\mathbf u(x)\right\}</script><p>where</p>
<script type="math/tex; mode=display">
\begin{align*}
\boldsymbol\eta &= \left(\begin{matrix}\frac{\mu}{\sigma^2}\\\frac {-1} {2\sigma^2}\end{matrix}\right) &h(x) &= \frac{1}{\sqrt{2\pi}}\\
\mathbf u(x) &= \left(\begin{matrix}x\\x^2\end{matrix}\right) &g(\boldsymbol\eta) &= \sqrt{-2\eta_2}\exp\left(\frac{\eta_1^2}{4\eta_2}\right)
\end{align*}</script><h4 id="Maximum-likelihood-and-sufficient-statistics"><a href="#Maximum-likelihood-and-sufficient-statistics" class="headerlink" title="Maximum likelihood and sufficient statistics"></a>Maximum likelihood and sufficient statistics</h4><p>Likelihood function</p>
<script type="math/tex; mode=display">
p(\mathbf{X} \vert \boldsymbol{\eta})=\left(\prod_{n=1}^{N} h\left(\mathbf{x}_{n}\right)\right) g(\boldsymbol{\eta})^{N} \exp \left\{\boldsymbol{\eta}^{T} \sum_{n=1}^{N} \mathbf{u}\left(\mathbf{x}_{n}\right)\right\}</script><p>Condition of maximum likelihood estimator $\boldsymbol\eta_\text{ML}$</p>
<script type="math/tex; mode=display">
\begin{align*}
-\nabla\ln g(\boldsymbol \eta_\text{ML})=\frac 1 N& \sum\limits_{n=1}^N\mathbf u(\mathbf x_n)\\
&\uparrow\text{Sufficient statistic}
\end{align*}</script><p>The solution for the ML estimator only depends on $\sum\limits_{n=1}^N\mathbf u(\mathbf x_n)$, which is called the sufficient statistic of the distribution.</p>
<p>For example,</p>
<p>Bernoulli distribution $\mathbf u(x) = x$, so we only keep the sum of the data points; Gaussian distribution $\mathbf u(x) = \left(\begin{matrix}x\\x^2\end{matrix}\right)$, we need to keep both the sum of data points and the sum of the square.</p>
<h4 id="Conjugate-Priors"><a href="#Conjugate-Priors" class="headerlink" title="Conjugate Priors"></a>Conjugate Priors</h4><p>Seek a prior that is <strong>conjugate</strong> to the likelihood function: the posterior distribution has the <strong>same functional form</strong> as the prior.</p>
<p>For any member of the exponential family, there exists a conjugate prior</p>
<script type="math/tex; mode=display">
\text{prior} = p(\boldsymbol\eta\vert\chi,\nu) = f(\chi,\nu)g(\boldsymbol\eta)^\nu\exp\left\{\nu\boldsymbol\eta^\text T\chi\right\}</script><p>where</p>
<ul>
<li>$f(\chi,\nu)$ is a normalization coefficient</li>
<li>$g(\boldsymbol\eta)$ is the normalization coefficient of the exponential family.</li>
</ul>
<p>Recall that</p>
<script type="math/tex; mode=display">
\text{Likelihood} =p(\mathbf{X} \vert \boldsymbol{\eta})=\left(\prod_{n=1}^{N} h\left(\mathbf{x}_{n}\right)\right) g(\boldsymbol{\eta})^{N} \exp \left\{\boldsymbol{\eta}^{T} \sum_{n=1}^{N} \mathbf{u}\left(\mathbf{x}_{n}\right)\right\}</script><p>Multiply the prior and the likelihood, the posterior is</p>
<script type="math/tex; mode=display">
\text{Posterior} \propto g(\boldsymbol\eta)^{\nu+N}\exp\left\{\boldsymbol\eta^\text T \left(\sum\limits_{n=1}^N\mathbf u(\mathbf x_n)+\nu\chi\right)\right\}</script><p>which is in the same functional form as the prior.</p>
<ul>
<li>$\nu$: effective number of pseudo-observations in the prior</li>
<li>$\chi$: value of the sufficient statistic for the pseudo-observations</li>
</ul>
<h3 id="Non-informative-Priors"><a href="#Non-informative-Priors" class="headerlink" title="Non-informative Priors"></a>Non-informative Priors</h3><p>Used when little is known about the prior distribution.</p>
<p>Have as little influence on the posterior distribution as possible.</p>
<p>Cons of choose constant as the prior</p>
<ul>
<li>If the domain of the parameter $\lambda$ is unbounded, the integral over $\lambda$ diverges, hence the prior cannot be normalized and is <strong>improper</strong>.</li>
<li>By changing the variable(e.g., $\lambda=\eta^2$), the density over the new variable may not be constant.</li>
</ul>
<p>Example: $\text{Gam}(\lambda\vert a_0,b_0)$ where $a_0=b_0=0$.</p>
<h3 id="Non-parametric-Methods"><a href="#Non-parametric-Methods" class="headerlink" title="Non-parametric Methods"></a>Non-parametric Methods</h3><p><strong>Limitation of parametric methods:</strong></p>
<p>The chosen density might be a poor model of the distribution that generates the data. Multimodal data can never be captured by a unimodal Gaussian.</p>
<h4 id="Histogram-Methods"><a href="#Histogram-Methods" class="headerlink" title="Histogram Methods"></a>Histogram Methods</h4><p><img src="https://picst.sunbangyan.cn/2023/11/21/d15a31fe2fd078f7148522e283831252.jpeg" style="zoom:50%;" /></p>
<script type="math/tex; mode=display">
p_i = \frac{n_i}{N\Delta_i}</script><p>where $\Delta$ acts as a smoothing parameter.</p>
<p>Cons: Curse of Dimensionality</p>
<h3 id="K-Nearest-Neighbors"><a href="#K-Nearest-Neighbors" class="headerlink" title="K-Nearest-Neighbors"></a>K-Nearest-Neighbors</h3><h2 id="Chapter-4-Linear-Models-for-Regression"><a href="#Chapter-4-Linear-Models-for-Regression" class="headerlink" title="Chapter 4 - Linear Models for Regression"></a>Chapter 4 - Linear Models for Regression</h2><h2 id="Chapter-5-Linear-Models-for-Classification"><a href="#Chapter-5-Linear-Models-for-Classification" class="headerlink" title="Chapter 5 - Linear Models for Classification"></a>Chapter 5 - Linear Models for Classification</h2><h3 id="Three-Approaches-to-Classification"><a href="#Three-Approaches-to-Classification" class="headerlink" title="Three Approaches to Classification"></a>Three Approaches to Classification</h3><ul>
<li>Use discriminant functions directly</li>
<li>Infer the posterior probabilities with generative models</li>
<li>Directly construct posterior conditional class probabilities</li>
</ul>
<h3 id="Discriminant-Functions"><a href="#Discriminant-Functions" class="headerlink" title="Discriminant Functions"></a>Discriminant Functions</h3><p><strong>Discriminant Functions for $N$ classes</strong></p>
<ul>
<li>use $N$ two-way discriminant functions</li>
<li>use $\frac{N(N-1)}{2}$ two-way discriminant functions</li>
</ul>
<h3 id="Least-Square-Classification"><a href="#Least-Square-Classification" class="headerlink" title="Least Square Classification"></a>Least Square Classification</h3><ul>
<li>Reduce <strong>classification</strong> to least squares <strong>regression</strong>.</li>
<li>Treat each class as a separate problem, pick the max.</li>
</ul>
<p>Least square regression is sensitive to outliers, use logistic regression to solve this problem:</p>
<p><img src="https://s2.loli.net/2023/11/07/bdLjc4yTiRkGEI7.png" alt="image.png" style="zoom: 33%;" /></p>
<h3 id="Fisher’s-Linear-Discriminants-LDA"><a href="#Fisher’s-Linear-Discriminants-LDA" class="headerlink" title="Fisher’s Linear Discriminants(LDA)"></a>Fisher’s Linear Discriminants(LDA)</h3><p>See the <a target="_blank" rel="noopener" href="https://github.com/GuTaoZi/CS329_Machine_Learning/blob/main/Lab_Materials/Lab06.Linear%20Discriminant%20Analysis/Lab6.Linear%20Discriminant%20Analysis.ipynb">course material for Lab06: LDA</a></p>
<p><img src="https://raw.githubusercontent.com/GuTaoZi/CS329_Machine_Learning/daad03239f0966cd39434cf8312ce640a226cb1f/Lab_Materials/Lab06.Linear%20Discriminant%20Analysis/images/example.png" style="zoom:50%;" /></p>
<h3 id="Perceptron"><a href="#Perceptron" class="headerlink" title="Perceptron"></a>Perceptron</h3><script type="math/tex; mode=display">
y(\mathbf x)=f(\mathbf w^\text T\phi(\mathbf x))\quad f(a) = \left\{\begin{matrix}+1,a\ge0 \\ -1, a<0\end{matrix}\right.</script><h4 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h4><p>Criterion:</p>
<script type="math/tex; mode=display">
E_P(\mathbf w)=-\sum\limits_{n\in\mathcal M}\mathbf w^\text T\phi_nt_n</script><p>where $t_n\in\{1,-1\}$ is the label. </p>
<script type="math/tex; mode=display">
\mathbf w^{(\tau+1)}=\mathbf w^\tau-\eta\nabla E_P(\mathbf w)=\mathbf w^\tau + \eta\phi_nt_n</script><p>where $\eta$ is the learning rate.</p>
<script type="math/tex; mode=display">
-\mathbf (w^{(\tau+1)})^\text T\phi_nt_n<-(w^{\tau})^\text T\phi_nt_n</script><p>indicating the convergence of perceptron training.</p>
<h4 id="Simplified-Training"><a href="#Simplified-Training" class="headerlink" title="Simplified Training"></a>Simplified Training</h4><script type="math/tex; mode=display">
\mathbf w^\text{new}=\mathbf w^\text{old}-0.5(y_n-t_n)x_n</script><ul>
<li>guaranteed to find a set of weights that gets the right answer on the whole training set if any such a set exists.</li>
<li>no need to choose a learning rate.</li>
</ul>
<h3 id="Probabilistic-Generative-Models"><a href="#Probabilistic-Generative-Models" class="headerlink" title="Probabilistic Generative Models"></a>Probabilistic Generative Models</h3><script type="math/tex; mode=display">
p(C_1\vert\mathbf x)=\frac{p(C_1)p(\mathbf x\vert C_1)}{p(\mathbf x)}=\frac{1}{1+e^{-z}}=\sigma(z)</script><p>where $z$ is called the logit</p>
<script type="math/tex; mode=display">
z=\ln\frac{p(C_1)p(x\vert C_1)}{\sum\limits_{i\neq 1}p(C_i)p(x\vert C_i)}=\ln \frac{p(C_1\vert \mathbf x)}{1-p(C_1\vert \mathbf x)}</script><h4 id="K-Case-Classification"><a href="#K-Case-Classification" class="headerlink" title="K-Case Classification"></a>K-Case Classification</h4><script type="math/tex; mode=display">
p(C_k\vert\mathbf x)=\frac{p(C_k)p(\mathbf x\vert C_k)}{\sum\limits_{i}p(C_i)p(x\vert C_i)}</script><h4 id="Generative-ML-Gaussian-Mixtures"><a href="#Generative-ML-Gaussian-Mixtures" class="headerlink" title="Generative: ML Gaussian Mixtures"></a>Generative: ML Gaussian Mixtures</h4><script type="math/tex; mode=display">
\begin{array}{l}
p(x, C_{1})=p(C_{1}) p(x \vert C_{1})=\pi \mathcal N(x \vert \mu_{1}, \Sigma) \\
p(x, C_{2})=p(C_{2}) p(x \vert C_{2})=(1-\pi) \mathcal N(x \vert \mu_{2}, \Sigma)
\end{array}</script><p>Likelihood $p\left(\boldsymbol{t}, \boldsymbol{X} \vert \pi, \mu_{1}, \mu_{2}, \Sigma\right)=\prod_{n=1}^{N}\left[\pi N\left(x_{n} \vert \mu_{1}, \Sigma\right)\right]^{t_{n}}\left[(1-\pi) N\left(x_{n} \vert \mu_{2}, \Sigma\right)\right]^{1-t_{n}}$</p>
<script type="math/tex; mode=display">
\begin{align*}
\pi_{M L}&=\frac{1}{N} \sum_{n=1}^{N} t_{n}=\frac{N_{1}}{N}=\frac{N_{1}}{N_{1}+N_{2}} \\
\mu_{1 \mathrm{ML}}&=\frac{1}{N_{1}} \sum_{n=1}^{N} t_{n} x_{n} \\ \mu_{2 \mathrm{ML}}&=\frac{1}{N_{2}} \sum_{n=1}^{N}\left(1-t_{n}\right) x_{n} \\
\Sigma&=\pi \Sigma_{1}+(1-\pi) \Sigma_{2} \\ \Sigma_{i \mathrm{ML}}&=\frac{1}{N_{i}} \sum_{x_{n} \in C_{i}}\left(x_{n}-\mu_{i}\right)\left(x_{n}-\mu_{i}\right)^{T} \quad \mathrm{i}=1,2
\end{align*}</script><p>这里各个参数的意义待补。</p>
<h4 id="Generative-MAP-Gaussian-Mixtures"><a href="#Generative-MAP-Gaussian-Mixtures" class="headerlink" title="Generative: MAP Gaussian Mixtures"></a>Generative: MAP Gaussian Mixtures</h4><script type="math/tex; mode=display">
\pi_0=\frac{N_{10}}{N_{10}+N_{20}}, x\in\mathcal C_i\sim(x\vert\mu_{i0},\Sigma_{i0})</script><script type="math/tex; mode=display">
\pi_\text{MAP} = \frac{N_1+N_{10}}{N+N_0}=\frac{N_1+N_{10}}{N_1+N_2+N_{10}+N_{20}}</script><script type="math/tex; mode=display">
\left\{\begin{align*}\Sigma_{i\text{MAP}}^{-1}&=\Sigma_{i\text{ML}}^{-1}+\Sigma_{i0}^{-1}\\\Sigma_{i\text{MAP}}^{-1}\mu_{i\text{MAP}}&=\Sigma_{i\text{ML}}^{-1}\mu_{i\text{ML}}+\Sigma_{i0}^{-1}\mu_{i0}\end{align*}\right.</script><p>这里各个参数的意义待补。</p>
<h3 id="Probabilistic-Discriminative-Models"><a href="#Probabilistic-Discriminative-Models" class="headerlink" title="Probabilistic Discriminative Models"></a>Probabilistic Discriminative Models</h3><h3 id="Bayesian-Information-Criterion"><a href="#Bayesian-Information-Criterion" class="headerlink" title="Bayesian Information Criterion"></a>Bayesian Information Criterion</h3><h2 id="Chapter-6-Neural-Networks"><a href="#Chapter-6-Neural-Networks" class="headerlink" title="Chapter 6 - Neural Networks"></a>Chapter 6 - Neural Networks</h2><p><img src="https://s2.loli.net/2023/01/01/8pS9IbAPfWXDOgt.png" alt=""></p>
<h2 id="Chapter-7-Sparse-Kernel-Machines"><a href="#Chapter-7-Sparse-Kernel-Machines" class="headerlink" title="Chapter 7 - Sparse Kernel Machines"></a>Chapter 7 - Sparse Kernel Machines</h2><h3 id="Support-Vector-Machines"><a href="#Support-Vector-Machines" class="headerlink" title="Support Vector Machines"></a>Support Vector Machines</h3><p>Model: $\quad y(\mathbf x) = \mathbf w^\text T \phi(\mathbf x) + b$</p>
<p>Distance of a point to the decision surface</p>
<script type="math/tex; mode=display">
\frac{t_ny(\mathbf x_n)}{\vert\vert \mathbf w \vert\vert} = \frac{t_n(\mathbf w^\text T \phi(\mathbf x) + b)}{\vert\vert \mathbf w \vert\vert}</script><p>Rescaling $\mathbf w$ and $b$, the point closest to the surface(active constraint) satisfies:</p>
<script type="math/tex; mode=display">
\quad t_n(\mathbf w^\text T \phi(\mathbf x) + b)=1</script><p>Then the classification problem becomes:</p>
<script type="math/tex; mode=display">
\mathop{\arg\min}\limits_{\mathbf w, b} \frac 1 2 \vert\vert\mathbf  w\vert\vert^2 \text{ subject to } t_n(\mathbf w^\text T \phi(\mathbf x) + b)\ge 1,\ n=1,\dots,N</script><h4 id="Hard-Margin-Classifier"><a href="#Hard-Margin-Classifier" class="headerlink" title="Hard Margin Classifier"></a>Hard Margin Classifier</h4><p>The classification problem:</p>
<script type="math/tex; mode=display">
\mathop{\arg\min}\limits_{\mathbf w, b} \sum\limits_{n=1}^N E_\infty (y(\mathbf x_n)t_n-1)+\lambda\vert\vert\mathbf  w\vert\vert^2,\quad\lambda>0</script><p>where</p>
<script type="math/tex; mode=display">
E_\infty(z) = \left\{\begin{matrix}0, &z\ge 0 \\ \infty, &z<0\end{matrix}\right.</script><h4 id="Soft-Margin-Classifier"><a href="#Soft-Margin-Classifier" class="headerlink" title="Soft Margin Classifier"></a>Soft Margin Classifier</h4><p>Introduce slack variables $\xi_n\ge 0, n=1,\dots,N$ (sometimes $\xi_n&lt;0$ is allowed)</p>
<p>The classification problem:</p>
<script type="math/tex; mode=display">
\begin{align*}
&\mathop{\arg\min}\limits_{\mathbf w, b}\ \ C\sum\limits_{n=1}^N \xi_n+\frac 1 2 \vert\vert\mathbf  w\vert\vert^2 \\&\text{ subject to } t_n(\mathbf w^\text T \phi(\mathbf x) + b)\ge 1,\ n=1,\dots,N
\end{align*}</script><p>where $C&gt;0$ is the trade-off between minimizing training errors and controlling  model complexity.</p>
<h4 id="SVMs-and-Logistic-Regression"><a href="#SVMs-and-Logistic-Regression" class="headerlink" title="SVMs and Logistic Regression"></a>SVMs and Logistic Regression</h4><h4 id="Multiclass-SVMs"><a href="#Multiclass-SVMs" class="headerlink" title="Multiclass SVMs"></a>Multiclass SVMs</h4><ol>
<li>One vs. Rest: $K$ separate SVMs<ul>
<li>Can lead to inconsistent results</li>
<li>Imbalanced training sets</li>
</ul>
</li>
<li>One vs. One: $\frac{K(K-1)}{2}$ SVMs<ul>
<li>dead zone</li>
</ul>
</li>
</ol>
<h4 id="SVMs-for-Regression"><a href="#SVMs-for-Regression" class="headerlink" title="SVMs for Regression"></a>SVMs for Regression</h4><p>过的很快，只用了一分半</p>
<h3 id="※Relevance-Vector-Machines"><a href="#※Relevance-Vector-Machines" class="headerlink" title="※Relevance Vector Machines"></a>※Relevance Vector Machines</h3><p>Given an input vector $\mathbf x$, the conditional distribution for a real-valued target variable $t$:</p>
<script type="math/tex; mode=display">
p(t\vert\mathbf  x,\mathbf w,\beta) = \mathcal N(t\vert y(\mathbf x),\beta^{-1})</script><p>where $\beta=\sigma^{-2}$ is the noise precision.</p>
<p>The mean is given by a linear model, which can be written in an SVM-like form:</p>
<script type="math/tex; mode=display">
y(\mathbf x) = \sum\limits_{n=1}^N w_nk(\mathbf x,\mathbf x_n)+b</script><p>where $k(\mathbf x,\mathbf x_n)=\phi(\mathbf x)^\text T \phi(\mathbf x_n)$ is the kernel, and $b$ is 616.a bias parameter.</p>
<p>……</p>
<p>后面翘课了。</p>
<h2 id="Chapter-8-Mixture-Models-and-EM-Learning"><a href="#Chapter-8-Mixture-Models-and-EM-Learning" class="headerlink" title="Chapter 8 - Mixture Models and EM Learning"></a>Chapter 8 - Mixture Models and EM Learning</h2><p>翘课了。</p>
<h2 id="Chapter-9-Sequential-Data"><a href="#Chapter-9-Sequential-Data" class="headerlink" title="Chapter 9 - Sequential Data"></a>Chapter 9 - Sequential Data</h2><p>Conditional data: independent of the previous states</p>
<p>Sequential data: dependent of the previous states</p>
<p><strong>Markov models</strong></p>
<ul>
<li><p>first-order:</p>
<script type="math/tex; mode=display">
\begin{align*}
p(\mathbf x_1,\dots,\mathbf x_N) &= p(\mathbf x_1) \prod\limits_{n=2}^N p(\mathbf x_n\vert\mathbf x_{n-1})\\
p(\mathbf x_n\vert\mathbf x_1,\dots,\mathbf x_{n-1}) &= p(\mathbf x_n\vert\mathbf x_{n-1})
\end{align*}</script></li>
<li><p>second-order:</p>
<script type="math/tex; mode=display">
p(\mathbf x_1,\dots,\mathbf x_N) = p(\mathbf x_1)p(\mathbf x_2\vert\mathbf x_1) \prod\limits_{n=3}^N p(\mathbf x_n\vert\mathbf x_{n-1},\mathbf x_{n-2})</script></li>
</ul>
<h3 id="Hidden-Markov-Models"><a href="#Hidden-Markov-Models" class="headerlink" title="Hidden Markov Models"></a>Hidden Markov Models</h3><p>For each observation $\mathbf x_n$, introduce latent variable $\mathbf z_n$, such that $\mathbf z_{n+1}\perp!!!!\perp \mathbf z_{n-1} \vert \mathbf z_n$</p>
<script type="math/tex; mode=display">
p(\mathbf x_1,\dots,\mathbf x_N,\mathbf z_1,\dots,\mathbf z_N) = p(\mathbf z_1)[\prod\limits_{n=2}^N]p(\mathbf z_n\vert\mathbf z_{n-1})\prod\limits_{n=1}^N p(\mathbf x_n\vert\mathbf z_n)</script><p>Use 1-of-K encoding, the latent variable is K-dimensional binary vector. The transition probability matrix $A_{j,k}\equiv p(z_{n,k}=1\mid z_{n-1,j}=1)$. This matrix satisfies $\sum\limits_{k} A_{jk}=1$ therefore has $K(K-1)$ independent parameters.</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Machine-Learning/" rel="tag"># Machine Learning</a>
              <a href="/tags/Artificial-Intelligence/" rel="tag"># Artificial Intelligence</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/07/28/2023%E5%9F%B9%E5%85%BB%E6%96%B9%E6%A1%88%E8%A7%A3%E8%AF%BB%E6%95%99%E7%A8%8B/" rel="prev" title="SUSTech 培养方案指南 2023 by 咕桃">
      <i class="fa fa-chevron-left"></i> SUSTech 培养方案指南 2023 by 咕桃
    </a></div>
      <div class="post-nav-item">
    <a href="/2023/09/12/CS323_Notes/" rel="next" title="CS323 Compilers Notes">
      CS323 Compilers Notes <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
  <script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
  <div id="gitalk-container"></div>
  <script>
  const gitalk = new Gitalk({
    clientID: '79118b0b29b4170f24af',
    clientSecret: '48ee47026d13b8a3a954b2b089ea320510282527',
    repo: 'GuTaoZi.github.io',      // The repository of store comments,
    owner: 'GuTaoZi',
    admin: ['GuTaoZi'],
    id: location.pathname,      // Ensure uniqueness and length less than 50
    distractionFreeMode: false  // Facebook-like distraction free mode
  })
  gitalk.render('gitalk-container')
  </script>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Outline"><span class="nav-number">1.</span> <span class="nav-text">Outline</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Chapter-1-Introduction"><span class="nav-number">2.</span> <span class="nav-text">Chapter 1 - Introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Concepts"><span class="nav-number">2.1.</span> <span class="nav-text">Concepts</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Linear-Optimization-Model"><span class="nav-number">2.2.</span> <span class="nav-text">Linear Optimization Model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Euclidean-Distance-Optimization"><span class="nav-number">2.3.</span> <span class="nav-text">Euclidean Distance Optimization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Convex-Optimization"><span class="nav-number">2.4.</span> <span class="nav-text">Convex Optimization</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Unconstrained-optimization"><span class="nav-number">2.4.1.</span> <span class="nav-text">Unconstrained optimization</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Gradient-descent"><span class="nav-number">2.4.1.1.</span> <span class="nav-text">Gradient descent</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Gauss-Newton%E2%80%99s-Method"><span class="nav-number">2.4.1.2.</span> <span class="nav-text">Gauss-Newton’s Method</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Batch-Gradient-Descent"><span class="nav-number">2.4.1.3.</span> <span class="nav-text">Batch Gradient Descent</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Stochastic-Gradient-Descent"><span class="nav-number">2.4.1.4.</span> <span class="nav-text">Stochastic Gradient Descent</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Constrained-optimization"><span class="nav-number">2.4.2.</span> <span class="nav-text">Constrained optimization</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Non-convex-Optimization"><span class="nav-number">2.5.</span> <span class="nav-text">Non-convex Optimization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Algorithms"><span class="nav-number">2.6.</span> <span class="nav-text">Algorithms</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Chapter-2-Preliminary"><span class="nav-number">3.</span> <span class="nav-text">Chapter 2 - Preliminary</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Curve-Fitting-and-Regularization"><span class="nav-number">3.1.</span> <span class="nav-text">Curve Fitting and Regularization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Probabilities-Theory"><span class="nav-number">3.2.</span> <span class="nav-text">Probabilities Theory</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Basic-Concepts"><span class="nav-number">3.2.1.</span> <span class="nav-text">Basic Concepts</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Gaussian-Distribution"><span class="nav-number">3.2.2.</span> <span class="nav-text">Gaussian Distribution</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Likelihood-Function"><span class="nav-number">3.2.3.</span> <span class="nav-text">Likelihood Function</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Properties-of-mu-ML-and-sigma-2-ML"><span class="nav-number">3.2.4.</span> <span class="nav-text">Properties of $\mu_{ML}$ and $\sigma^2_{ML}$</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Curve-fitting-re-visited"><span class="nav-number">3.2.5.</span> <span class="nav-text">Curve fitting re-visited</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MAP-Maximum-Posteriori"><span class="nav-number">3.2.6.</span> <span class="nav-text">MAP: Maximum Posteriori</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Bayesian-Curve-Fitting"><span class="nav-number">3.2.7.</span> <span class="nav-text">Bayesian Curve Fitting</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Model-Selection"><span class="nav-number">3.3.</span> <span class="nav-text">Model Selection</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Curse-of-Dimensionality"><span class="nav-number">3.4.</span> <span class="nav-text">Curse of Dimensionality</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Decision-Theory"><span class="nav-number">3.5.</span> <span class="nav-text">Decision Theory</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Confusion-Matrix"><span class="nav-number">3.5.1.</span> <span class="nav-text">Confusion Matrix</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Receiver-Operating-Characteristic-Curve"><span class="nav-number">3.5.2.</span> <span class="nav-text">Receiver Operating Characteristic Curve</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Minimizing-the-misclassification-rate"><span class="nav-number">3.5.3.</span> <span class="nav-text">Minimizing the misclassification rate</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Minimizing-the-expected-loss"><span class="nav-number">3.5.4.</span> <span class="nav-text">Minimizing the expected loss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Reject-Option"><span class="nav-number">3.5.5.</span> <span class="nav-text">Reject Option</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Inference-and-Decision"><span class="nav-number">3.5.6.</span> <span class="nav-text">Inference and Decision</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Loss-functions-for-regression"><span class="nav-number">3.5.7.</span> <span class="nav-text">Loss functions for regression</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Method-1-Calculus-of-Variations"><span class="nav-number">3.5.7.1.</span> <span class="nav-text">Method 1. Calculus of Variations</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Method-2-Expanding-the-square-term"><span class="nav-number">3.5.7.2.</span> <span class="nav-text">Method 2. Expanding the square term</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Information-Theory"><span class="nav-number">3.6.</span> <span class="nav-text">Information Theory</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Entropy-statistical"><span class="nav-number">3.6.1.</span> <span class="nav-text">Entropy(statistical)</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Discrete"><span class="nav-number">3.6.1.1.</span> <span class="nav-text">Discrete</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Entropy"><span class="nav-number">3.6.2.</span> <span class="nav-text">Entropy</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Conditional-Entropy"><span class="nav-number">3.6.3.</span> <span class="nav-text">Conditional Entropy</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Relative-Entropy-The-Kullback-Leibler-Divergence"><span class="nav-number">3.6.4.</span> <span class="nav-text">Relative Entropy (The Kullback-Leibler Divergence)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Cross-Entropy-for-Machine-Learning"><span class="nav-number">3.6.5.</span> <span class="nav-text">Cross Entropy for Machine Learning</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Mutual-Information"><span class="nav-number">3.6.6.</span> <span class="nav-text">Mutual Information</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Information-Gain"><span class="nav-number">3.6.7.</span> <span class="nav-text">Information Gain</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Chapter-3-Distributions"><span class="nav-number">4.</span> <span class="nav-text">Chapter 3 - Distributions</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Binary-Distributions"><span class="nav-number">4.1.</span> <span class="nav-text">Binary Distributions</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Bernoulli-Distribution"><span class="nav-number">4.1.1.</span> <span class="nav-text">Bernoulli Distribution</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Binomial-Distribution"><span class="nav-number">4.1.2.</span> <span class="nav-text">Binomial Distribution</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Beta-Distribution"><span class="nav-number">4.1.3.</span> <span class="nav-text">Beta Distribution</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Multinomial-Distributions"><span class="nav-number">4.2.</span> <span class="nav-text">Multinomial Distributions</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-of-K-coding-scheme"><span class="nav-number">4.2.1.</span> <span class="nav-text">1-of-K coding scheme</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Multinomial-Distribution"><span class="nav-number">4.2.2.</span> <span class="nav-text">Multinomial Distribution</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Dirichlet-Distribution"><span class="nav-number">4.2.3.</span> <span class="nav-text">Dirichlet Distribution</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Gaussian-Distributions"><span class="nav-number">4.3.</span> <span class="nav-text">Gaussian Distributions</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Central-Limit-Theorem"><span class="nav-number">4.3.1.</span> <span class="nav-text">Central Limit Theorem</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Moments-of-the-Multivariate-Gaussian"><span class="nav-number">4.3.2.</span> <span class="nav-text">Moments of the Multivariate Gaussian</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Properties-of-Gaussians"><span class="nav-number">4.3.3.</span> <span class="nav-text">Properties of Gaussians</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Bayes%E2%80%99-Theorem-for-Gaussian-Variables-Slides"><span class="nav-number">4.3.4.</span> <span class="nav-text">Bayes’ Theorem for Gaussian Variables(Slides)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Conditional-Gaussian-distributions"><span class="nav-number">4.3.5.</span> <span class="nav-text">Conditional Gaussian distributions</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Bayes%E2%80%99-Theorem-for-Gaussian-Variables-Textbook"><span class="nav-number">4.3.6.</span> <span class="nav-text">Bayes’ Theorem for Gaussian Variables(Textbook)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Maximum-Likelihood-for-the-Gaussian"><span class="nav-number">4.3.7.</span> <span class="nav-text">Maximum Likelihood for the Gaussian</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Sequential-estimation"><span class="nav-number">4.3.8.</span> <span class="nav-text">Sequential estimation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Bayesian-Inference-for-the-Gaussian"><span class="nav-number">4.3.9.</span> <span class="nav-text">Bayesian Inference for the Gaussian</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Student%E2%80%99s-t-distribution"><span class="nav-number">4.3.10.</span> <span class="nav-text">Student’s t-distribution</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Periodic-variables"><span class="nav-number">4.3.11.</span> <span class="nav-text">Periodic variables</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Mixtures-of-Gaussians"><span class="nav-number">4.3.12.</span> <span class="nav-text">Mixtures of Gaussians</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Exponential-Families"><span class="nav-number">4.4.</span> <span class="nav-text">Exponential Families</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Maximum-likelihood-and-sufficient-statistics"><span class="nav-number">4.4.1.</span> <span class="nav-text">Maximum likelihood and sufficient statistics</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Conjugate-Priors"><span class="nav-number">4.4.2.</span> <span class="nav-text">Conjugate Priors</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Non-informative-Priors"><span class="nav-number">4.5.</span> <span class="nav-text">Non-informative Priors</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Non-parametric-Methods"><span class="nav-number">4.6.</span> <span class="nav-text">Non-parametric Methods</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Histogram-Methods"><span class="nav-number">4.6.1.</span> <span class="nav-text">Histogram Methods</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#K-Nearest-Neighbors"><span class="nav-number">4.7.</span> <span class="nav-text">K-Nearest-Neighbors</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Chapter-4-Linear-Models-for-Regression"><span class="nav-number">5.</span> <span class="nav-text">Chapter 4 - Linear Models for Regression</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Chapter-5-Linear-Models-for-Classification"><span class="nav-number">6.</span> <span class="nav-text">Chapter 5 - Linear Models for Classification</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Three-Approaches-to-Classification"><span class="nav-number">6.1.</span> <span class="nav-text">Three Approaches to Classification</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Discriminant-Functions"><span class="nav-number">6.2.</span> <span class="nav-text">Discriminant Functions</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Least-Square-Classification"><span class="nav-number">6.3.</span> <span class="nav-text">Least Square Classification</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Fisher%E2%80%99s-Linear-Discriminants-LDA"><span class="nav-number">6.4.</span> <span class="nav-text">Fisher’s Linear Discriminants(LDA)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Perceptron"><span class="nav-number">6.5.</span> <span class="nav-text">Perceptron</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Training"><span class="nav-number">6.5.1.</span> <span class="nav-text">Training</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Simplified-Training"><span class="nav-number">6.5.2.</span> <span class="nav-text">Simplified Training</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Probabilistic-Generative-Models"><span class="nav-number">6.6.</span> <span class="nav-text">Probabilistic Generative Models</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#K-Case-Classification"><span class="nav-number">6.6.1.</span> <span class="nav-text">K-Case Classification</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Generative-ML-Gaussian-Mixtures"><span class="nav-number">6.6.2.</span> <span class="nav-text">Generative: ML Gaussian Mixtures</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Generative-MAP-Gaussian-Mixtures"><span class="nav-number">6.6.3.</span> <span class="nav-text">Generative: MAP Gaussian Mixtures</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Probabilistic-Discriminative-Models"><span class="nav-number">6.7.</span> <span class="nav-text">Probabilistic Discriminative Models</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Bayesian-Information-Criterion"><span class="nav-number">6.8.</span> <span class="nav-text">Bayesian Information Criterion</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Chapter-6-Neural-Networks"><span class="nav-number">7.</span> <span class="nav-text">Chapter 6 - Neural Networks</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Chapter-7-Sparse-Kernel-Machines"><span class="nav-number">8.</span> <span class="nav-text">Chapter 7 - Sparse Kernel Machines</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Support-Vector-Machines"><span class="nav-number">8.1.</span> <span class="nav-text">Support Vector Machines</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Hard-Margin-Classifier"><span class="nav-number">8.1.1.</span> <span class="nav-text">Hard Margin Classifier</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Soft-Margin-Classifier"><span class="nav-number">8.1.2.</span> <span class="nav-text">Soft Margin Classifier</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SVMs-and-Logistic-Regression"><span class="nav-number">8.1.3.</span> <span class="nav-text">SVMs and Logistic Regression</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Multiclass-SVMs"><span class="nav-number">8.1.4.</span> <span class="nav-text">Multiclass SVMs</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SVMs-for-Regression"><span class="nav-number">8.1.5.</span> <span class="nav-text">SVMs for Regression</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E2%80%BBRelevance-Vector-Machines"><span class="nav-number">8.2.</span> <span class="nav-text">※Relevance Vector Machines</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Chapter-8-Mixture-Models-and-EM-Learning"><span class="nav-number">9.</span> <span class="nav-text">Chapter 8 - Mixture Models and EM Learning</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Chapter-9-Sequential-Data"><span class="nav-number">10.</span> <span class="nav-text">Chapter 9 - Sequential Data</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Hidden-Markov-Models"><span class="nav-number">10.1.</span> <span class="nav-text">Hidden Markov Models</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="咕桃"
      src="https://avatars.githubusercontent.com/u/109007949?v=4">
  <p class="site-author-name" itemprop="name">咕桃</p>
  <div class="site-description" itemprop="description">Just Do It, But Not Just Do It.</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">42</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/GuTaoZi" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;GuTaoZi" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:first_fan@outlook.com" title="E-Mail → mailto:first_fan@outlook.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">咕桃</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


</body>
</html>
