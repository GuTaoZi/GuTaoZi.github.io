<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"gutaozi.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":-1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"slideLeftBigIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Notes on PRML">
<meta property="og:type" content="article">
<meta property="og:title" content="CS329 Machine Learning Notes">
<meta property="og:url" content="https://gutaozi.github.io/2023/09/12/CS329_Notes/index.html">
<meta property="og:site_name" content="咕桃w！">
<meta property="og:description" content="Notes on PRML">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-09-12T02:20:32.703Z">
<meta property="article:modified_time" content="2023-10-07T15:00:47.892Z">
<meta property="article:author" content="咕桃">
<meta property="article:tag" content="Machine Learning">
<meta property="article:tag" content="Artificial Intelligence">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://gutaozi.github.io/2023/09/12/CS329_Notes/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>CS329 Machine Learning Notes | 咕桃w！</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>


</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">咕桃w！</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://gutaozi.github.io/2023/09/12/CS329_Notes/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars.githubusercontent.com/u/109007949?v=4">
      <meta itemprop="name" content="咕桃">
      <meta itemprop="description" content="Just Do It, But Not Just Do It.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="咕桃w！">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          CS329 Machine Learning Notes
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-09-12 10:20:32" itemprop="dateCreated datePublished" datetime="2023-09-12T10:20:32+08:00">2023-09-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-10-07 23:00:47" itemprop="dateModified" datetime="2023-10-07T23:00:47+08:00">2023-10-07</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CS/" itemprop="url" rel="index"><span itemprop="name">CS</span></a>
                </span>
            </span>

          
            <div class="post-description">Notes on PRML</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="Outline"><a href="#Outline" class="headerlink" title="Outline"></a>Outline</h2><ol>
<li>Introduction</li>
<li>Preliminary</li>
</ol>
<h2 id="Chapter-1-Introduction"><a href="#Chapter-1-Introduction" class="headerlink" title="Chapter 1 - Introduction"></a>Chapter 1 - Introduction</h2><h3 id="Concepts"><a href="#Concepts" class="headerlink" title="Concepts"></a>Concepts</h3><ul>
<li><strong>Machine Learning</strong>—minimization of some loss function for generalizing data sets with models.</li>
<li><strong>Datasets</strong>—annotated, indexed, organized</li>
<li><strong>Models</strong>—tree, distance, probabilistic, graph, bio-inspired</li>
<li><strong>Optimization</strong>—algorithms can minimize the loss</li>
</ul>
<h3 id="Linear-Optimization-Model"><a href="#Linear-Optimization-Model" class="headerlink" title="Linear Optimization Model"></a>Linear Optimization Model</h3><script type="math/tex; mode=display">
Y=AX+W,\quad W\sim \mathbf N(0,R)\\
L(x)=\frac 1 2 (Y-AX)^\text TR^{-1}(Y-AX)\\</script><p>Find $X^\star$ to minimize the loss function:</p>
<script type="math/tex; mode=display">
\begin{align*}
&X^\star=\min\limits_X(Y-AX)^\text TR^{-1}(Y-AX)\\
&\text {Let } \frac{\partial}{\partial X^\text T}(Y-AX)^\text TR^{-1}(Y-AX)=0\\
&\Rightarrow X^\star = (A^\text T R^{-1}A)A^{\text T}R^{-1}Y
\end{align*}</script><h3 id="Euclidean-Distance-Optimization"><a href="#Euclidean-Distance-Optimization" class="headerlink" title="Euclidean Distance Optimization"></a>Euclidean Distance Optimization</h3><p>Point $x_0$, model $\mathbf b^\text Tx=d$.</p>
<script type="math/tex; mode=display">
x^\star = \min\limits_{x}(x-x_0)^\text T(x-x_0), \text{s.t.}\ \mathbf{b}^\text Tx-d=0</script><p>Lagrange optimization:</p>
<script type="math/tex; mode=display">
\begin{align*}
d&=\mathbf b^\text T(x_0-\lambda \mathbf b)\\
\lambda &= \frac{\mathbf b^\text Tx_0-d}{\mathbf b^\text T\mathbf b}\\
L(x,\lambda)&=\frac 1 2 (x-x_0)^\text T(x-x_0)+\lambda(\mathbf b^\text Tx-d)\\
\frac{\partial L}{\partial x^\text T}&=x^\star-x_0+\lambda \mathbf b=0\\
x^\star&=x_0-\frac{(\mathbf b^\text Tx_0-d)\mathbf b}{\mathbf b^\text T\mathbf b}
\end{align*}</script><h3 id="Convex-Optimization"><a href="#Convex-Optimization" class="headerlink" title="Convex Optimization"></a>Convex Optimization</h3><h4 id="Unconstrained-optimization"><a href="#Unconstrained-optimization" class="headerlink" title="Unconstrained optimization"></a>Unconstrained optimization</h4><h5 id="Gradient-descent"><a href="#Gradient-descent" class="headerlink" title="Gradient descent"></a>Gradient descent</h5><script type="math/tex; mode=display">
f(x_{t+1})=f(x_t)-\eta\nabla f(x_t)^\text T(x-x_t)</script><h5 id="Gauss-Newton’s-Method"><a href="#Gauss-Newton’s-Method" class="headerlink" title="Gauss-Newton’s Method"></a>Gauss-Newton’s Method</h5><p>Use a second-order approximation to function:</p>
<script type="math/tex; mode=display">
f(x+\Delta x)\approx f(x)+\nabla f(x)^\text T\Delta x+\frac 1 2 \Delta x^\text T\nabla^2f(x)\Delta x</script><p>Choose $\Delta x$ to minimize above:</p>
<script type="math/tex; mode=display">
\Delta x=-[\nabla^2f(x)]^{-1}\nabla f(x)</script><p>Descent direction:</p>
<script type="math/tex; mode=display">
\nabla f(x)^\text T\Delta x= -\nabla f(x)^\text T[\nabla^2f(x)]^{-1}\nabla f(x)<0</script><h5 id="Batch-Gradient-Descent"><a href="#Batch-Gradient-Descent" class="headerlink" title="Batch Gradient Descent"></a>Batch Gradient Descent</h5><p>Minimize empirical loss, assuming it’s convex and unconstrained.</p>
<ul>
<li>Gradient descent on the empirical loss</li>
<li>Gradient is the average of the gradient for all samples</li>
<li>Very slow when $n$ is very large</li>
</ul>
<script type="math/tex; mode=display">
w^{k+1}\leftarrow w^k-\eta_t(\frac1 n \sum\limits_{i=1}^n\frac{\partial L(w,x_i,y_i)}{\partial w})</script><h5 id="Stochastic-Gradient-Descent"><a href="#Stochastic-Gradient-Descent" class="headerlink" title="Stochastic Gradient Descent"></a>Stochastic Gradient Descent</h5><p>Compute gradient from just one or a few samples</p>
<script type="math/tex; mode=display">
w^{k+1}\leftarrow w^k-\eta_t \frac{\partial L(w,x_i,y_i)}{\partial w}</script><h4 id="Constrained-optimization"><a href="#Constrained-optimization" class="headerlink" title="Constrained optimization"></a>Constrained optimization</h4><h5 id="Lagrange-methods"><a href="#Lagrange-methods" class="headerlink" title="Lagrange methods"></a>Lagrange methods</h5><h5 id="Bayesian-methods"><a href="#Bayesian-methods" class="headerlink" title="Bayesian methods"></a>Bayesian methods</h5><h3 id="Non-convex-Optimization"><a href="#Non-convex-Optimization" class="headerlink" title="Non-convex Optimization"></a>Non-convex Optimization</h3><h4 id="Heuristic-algorithms"><a href="#Heuristic-algorithms" class="headerlink" title="Heuristic algorithms"></a>Heuristic algorithms</h4><h4 id="Random-search"><a href="#Random-search" class="headerlink" title="Random search"></a>Random search</h4><h3 id="Algorithms"><a href="#Algorithms" class="headerlink" title="Algorithms"></a>Algorithms</h3><ul>
<li>Bayes</li>
<li>KNN</li>
<li>K-means</li>
<li>Decision Tree</li>
<li>SVM</li>
<li>Boosting</li>
<li>Ensemble Learning</li>
<li>Linear Statistical Learning</li>
<li>Nonlinear Statistical Learning</li>
<li>Deep Neural Networks</li>
<li>Generative Adversarial Networks</li>
<li>Bayesian Networks</li>
<li>Reinforcement Learning</li>
<li>Federated Learning</li>
</ul>
<h2 id="Chapter-2-Preliminary"><a href="#Chapter-2-Preliminary" class="headerlink" title="Chapter 2 - Preliminary"></a>Chapter 2 - Preliminary</h2><h3 id="Curve-Fitting-and-Regularization"><a href="#Curve-Fitting-and-Regularization" class="headerlink" title="Curve Fitting and Regularization"></a>Curve Fitting and Regularization</h3><p><strong>Polynomial Curve Fitting</strong></p>
<script type="math/tex; mode=display">
y(x,\mathbf{w})=w_{0}+w_{1}x+w_{2}x+...+w_Mx^M=\sum^M_{i=0}w_ix^i</script><p><strong>Sum-of-Squares Error Function</strong></p>
<script type="math/tex; mode=display">
E(\mathbf w)=\frac 1 2 \sum\limits_{n=1}^N\{y(x_n,\mathbf w)-t_n\}^2</script><p><strong>Root-Mean-Square (RMS) Error</strong></p>
<script type="math/tex; mode=display">
E_{\text{RMS}}=\sqrt{2E(\mathbf w^\star)/N}</script><p>where $\mathbf w^\star=\mathop{\text{argmin}}\limits_{\bf w}\ E(\bf w)$.</p>
<p><strong>Regularization</strong></p>
<p>Discourage the coefficients from reaching large values.</p>
<script type="math/tex; mode=display">
\tilde E(\mathbf w)=\frac 1 2 \sum\limits_{n=1}^N\{y(x_n,\mathbf w)-t_n\}^2 + {\color{red}\frac{\lambda}2 \| \mathbf w \| ^2}</script><p>where $|{\bf w}|={\bf w}^T{\bf w}=w_0^2+w_1^2+\cdots+w_M^2$. </p>
<blockquote>
<p>Note that often the coefficient $w_0$ is omitted from the regularizer because its inclusion causes the results to depend on the choice of origin for the target variable (Hastie et al., 2001), or it may be included but with its own regularization coefficient</p>
</blockquote>
<h3 id="Probabilities-Theory"><a href="#Probabilities-Theory" class="headerlink" title="Probabilities Theory"></a>Probabilities Theory</h3><h4 id="Basic-Concepts"><a href="#Basic-Concepts" class="headerlink" title="Basic Concepts"></a>Basic Concepts</h4><ul>
<li><p>Marginal/Joint/Conditional Probability</p>
</li>
<li><p>Sum/Product Rule</p>
</li>
<li><p>Probability Densities</p>
</li>
<li><p>Bayes’ Theorem</p>
<script type="math/tex; mode=display">
p(Y\vert X)=\frac{p(X\vert Y)p(Y)}{p(X)}</script></li>
<li><p>Prior/Posterior Probability</p>
</li>
<li><p>Transformed Densities</p>
<script type="math/tex; mode=display">
\begin{align*}
p_y(y)&=p_x(x)|\frac{dx}{dy}|\\
&=p_x(g(y))|g\prime(y)|
\end{align*}</script></li>
<li><p>Expectations</p>
</li>
<li><p>Variances and Covariances</p>
</li>
</ul>
<h4 id="Gaussian-Distribution"><a href="#Gaussian-Distribution" class="headerlink" title="Gaussian Distribution"></a>Gaussian Distribution</h4><ul>
<li><p>The Gaussian Distribution</p>
<script type="math/tex; mode=display">
\mathcal N(x|\mu,\sigma^2)=\frac 1 {(2\pi\sigma^2)^{1/2}}\exp\left\{-\frac 1 {2\sigma^2}(x-\mu)^2\right\}</script></li>
<li><p>Gaussian Mean and Variance</p>
<script type="math/tex; mode=display">
\begin{align*}
\mathbb E[x]&=\int_{-\infty}^\infty \mathcal N(x\vert \mu,\sigma^2)x dx = \mu\\
\mathbb E[x^2]&=\int_{-\infty}^\infty \mathcal N(x\vert \mu,\sigma^2)x^2 dx = \mu^2 + \sigma^2\\
\text{var}[x]&=\mathbb E[x^2]-\mathbb E[x]^2 = \sigma^2
\end{align*}</script></li>
<li><p>The Multivariate Gaussian</p>
<script type="math/tex; mode=display">
\mathcal N(\mathbf x|\mathbf\mu,\mathbf\Sigma)=\frac 1 {(2\pi)^{D/2}}\frac 1 {|\mathbf\Sigma|^{1/2}}\exp\left\{-\frac 1 2(\mathbf x-\mathbf\mu)^\text T\mathbf\Sigma^{-1}(\mathbf x - \mathbf \mu)\right\}</script></li>
</ul>
<h4 id="Likelihood-Function"><a href="#Likelihood-Function" class="headerlink" title="Likelihood Function"></a>Likelihood Function</h4><p>For a data set of independent observations $\mathbf x = (x_1,\cdots,x_N)^\text T$ of a Gaussian Distribution, its likelihood function is</p>
<script type="math/tex; mode=display">
p(\mathbf x \vert \mu,\sigma^2)=\prod\limits_{n=1}^N\mathcal N(x_n\vert\mu,\sigma^2)</script><p>Log Likelihood Function: </p>
<script type="math/tex; mode=display">
\ln p(\mathbf x|\mu,\sigma^2)=-\frac 1 {2\sigma^2}\sum\limits_{n=1}^N(x_n-\mu)^2 - \frac{N}2 \ln \sigma^2-\frac{N}2 \ln(2\pi)</script><p>By maximizing the log likelihood function, we have</p>
<script type="math/tex; mode=display">
\mu_{ML}=\frac 1 N \sum\limits_{n=1}^N x_n,\quad \sigma^2_{ML}=\frac 1 N  \sum\limits_{n=1}^N (x_n-\mu_{ML})^2</script><p>corresponding to the <strong>sample mean</strong> and the <strong>sample variance</strong>.</p>
<h4 id="Properties-of-mu-ML-and-sigma-2-ML"><a href="#Properties-of-mu-ML-and-sigma-2-ML" class="headerlink" title="Properties of $\mu_{ML}$ and $\sigma^2_{ML}$"></a>Properties of $\mu_{ML}$ and $\sigma^2_{ML}$</h4><p>The MLE will obtain the correct mean but will underestimate the true variance by a factor $\frac{N-1}{N}$ (bias).</p>
<script type="math/tex; mode=display">
\begin{align*}
\mathbb E[\mu_{ML}]&=\mu\\
\mathbb E[\sigma^2_{ML}]&=(\frac{N-1}N)\sigma^2\\
\widetilde \sigma^2&= (\frac N{N-1})\sigma^2_{ML}\\
&=\frac 1{N-1} \sum\limits_{n=1}^N (x_n-\mu_{ML})^2
\end{align*}</script><h4 id="Curve-fitting-re-visited"><a href="#Curve-fitting-re-visited" class="headerlink" title="Curve fitting re-visited"></a>Curve fitting re-visited</h4><p>Given $x$, the corresponding value of $t$ has a Gaussian distribution with a mean equal to the value $y(x, \mathbf w)$.</p>
<script type="math/tex; mode=display">
p(t\vert x,\mathbf w,\beta)=\mathcal N(t\vert y(x,\mathbf w),\beta^{-1})</script><p>where $\beta$ is the precision parameter corresponding to the inverse variance of the distribution: $\beta^{-1}=\sigma^2$.</p>
<p>Training data:</p>
<ul>
<li>Input values $\mathbf x=(x_1,\cdots,x_N)^\text T$</li>
<li>Target values $\mathbf t=(t_1,\cdots,t_N)^\text T$</li>
</ul>
<p>Likelihood function:</p>
<script type="math/tex; mode=display">
p(\mathbf t\vert \mathbf x,\mathbf w,\beta)=\prod\limits_{n=1}^N\mathcal N(t_n\vert y(x_n,\mathbf w),\beta^{-1})</script><p>Log likelihood function:</p>
<script type="math/tex; mode=display">
\ln p(\mathbf t\vert \mathbf x,\mathbf w,\beta)=-\frac\beta 2 \sum\limits_{n=1}^N\{y(x_n,\mathbf w)-t_n\}^2+\frac N 2 \ln \beta -\frac N 2 \ln(2\pi)</script><ul>
<li>The last two terms do not depend on $\bf w$, omitted.</li>
<li>Dividing a positive constant $\beta$ does not alter $\mathbf w_{ML}$, replace $\frac \beta 2$ with $\frac 1 2$.</li>
</ul>
<p>So <strong>maximizing the likelihood function</strong> is equivalent to <strong>minimizing the sum-of-squares error function</strong> $\sum\limits_{n=1}^N\{y(x_n,\mathbf w)-t_n\}^2$.</p>
<p>After obtaining $\mathbf w_{ML}$, we can further maximize the likelihood function w.r.t. $\beta$:</p>
<script type="math/tex; mode=display">
\frac 1 {\beta_{ML}}=\sum\limits_{n=1}^N\{y(x_n,\mathbf w_{ML})-t_n\}^2</script><p>Substitute $\mathbf w_{ML}$ and $\beta_{ML}$ back to get <strong>predictive distribution</strong>:</p>
<script type="math/tex; mode=display">
p(\mathbf t\vert \mathbf x,\mathbf w_{ML},\beta_{ML})=\prod\limits_{n=1}^N\mathcal N(t_n\vert y(x_n,\mathbf w_{ML}),\beta^{-1}_{ML})</script><h4 id="MAP-Maximum-Posteriori"><a href="#MAP-Maximum-Posteriori" class="headerlink" title="MAP: Maximum Posteriori"></a>MAP: Maximum Posteriori</h4><script type="math/tex; mode=display">
p(\mathbf w\vert \alpha)=\mathcal N(\mathbf w|\mathbf 0,\alpha^{-1}\mathbf I)=(\frac\alpha{2\pi})^{(M+1)/2} \exp\{-\frac\alpha 2 \mathbf w^\text{T}\mathbf w\}</script><script type="math/tex; mode=display">
\text{ref:}\mathcal N(\mathbf x|\mathbf\mu,\mathbf\Sigma)=\frac 1 {(2\pi)^{D/2}}\frac 1 {|\mathbf\Sigma|^{1/2}}\exp\left\{-\frac 1 2(\mathbf x-\mathbf\mu)^\text T\mathbf\Sigma^{-1}(\mathbf x - \mathbf \mu)\right\}</script><p>where $\alpha$ is the precision of the distribution(<em>hyperparameter</em>), and $M+1$ is the total number of elements in the vector $\bf w$ for an $M^\text{th}$ order polynomial.</p>
<p>Bayes’ Theorem: the posterior distribution for $\bf w$ is proportional to the product of the prior distribution and the likelihood function:</p>
<script type="math/tex; mode=display">
\begin{align*}
&p(\mathbf w \vert\mathbf x,\mathbf t,\alpha,\beta)&\propto\quad&p(\mathbf t\vert \mathbf x,\mathbf w,\beta)&p(\mathbf w\vert\alpha)\\
&\text{posteriori}&\propto\quad&\text{likelihood}&\text{priori}
\end{align*}</script><script type="math/tex; mode=display">
\beta\widetilde E(\mathbf w)=\frac\beta 2\sum\limits_{n=1}^N\{y(x_n,\mathbf w)-t_n\}^2+\frac\alpha 2 \mathbf w^\text{T}\mathbf w</script><p><strong>Maximizing the posterior distribution</strong> is equivalent to <strong>minimizing the regularized sum-of-squares error function</strong></p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Machine-Learning/" rel="tag"># Machine Learning</a>
              <a href="/tags/Artificial-Intelligence/" rel="tag"># Artificial Intelligence</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/07/28/2023%E5%9F%B9%E5%85%BB%E6%96%B9%E6%A1%88%E8%A7%A3%E8%AF%BB%E6%95%99%E7%A8%8B/" rel="prev" title="SUSTech 培养方案指南 2023 by 咕桃">
      <i class="fa fa-chevron-left"></i> SUSTech 培养方案指南 2023 by 咕桃
    </a></div>
      <div class="post-nav-item">
    <a href="/2023/09/12/CS323_Notes/" rel="next" title="CS323 Compilers Notes">
      CS323 Compilers Notes <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
  <script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
  <div id="gitalk-container"></div>
  <script>
  const gitalk = new Gitalk({
    clientID: '79118b0b29b4170f24af',
    clientSecret: '48ee47026d13b8a3a954b2b089ea320510282527',
    repo: 'GuTaoZi.github.io',      // The repository of store comments,
    owner: 'GuTaoZi',
    admin: ['GuTaoZi'],
    id: location.pathname,      // Ensure uniqueness and length less than 50
    distractionFreeMode: false  // Facebook-like distraction free mode
  })
  gitalk.render('gitalk-container')
  </script>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Outline"><span class="nav-number">1.</span> <span class="nav-text">Outline</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Chapter-1-Introduction"><span class="nav-number">2.</span> <span class="nav-text">Chapter 1 - Introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Concepts"><span class="nav-number">2.1.</span> <span class="nav-text">Concepts</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Linear-Optimization-Model"><span class="nav-number">2.2.</span> <span class="nav-text">Linear Optimization Model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Euclidean-Distance-Optimization"><span class="nav-number">2.3.</span> <span class="nav-text">Euclidean Distance Optimization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Convex-Optimization"><span class="nav-number">2.4.</span> <span class="nav-text">Convex Optimization</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Unconstrained-optimization"><span class="nav-number">2.4.1.</span> <span class="nav-text">Unconstrained optimization</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Gradient-descent"><span class="nav-number">2.4.1.1.</span> <span class="nav-text">Gradient descent</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Gauss-Newton%E2%80%99s-Method"><span class="nav-number">2.4.1.2.</span> <span class="nav-text">Gauss-Newton’s Method</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Batch-Gradient-Descent"><span class="nav-number">2.4.1.3.</span> <span class="nav-text">Batch Gradient Descent</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Stochastic-Gradient-Descent"><span class="nav-number">2.4.1.4.</span> <span class="nav-text">Stochastic Gradient Descent</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Constrained-optimization"><span class="nav-number">2.4.2.</span> <span class="nav-text">Constrained optimization</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Lagrange-methods"><span class="nav-number">2.4.2.1.</span> <span class="nav-text">Lagrange methods</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Bayesian-methods"><span class="nav-number">2.4.2.2.</span> <span class="nav-text">Bayesian methods</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Non-convex-Optimization"><span class="nav-number">2.5.</span> <span class="nav-text">Non-convex Optimization</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Heuristic-algorithms"><span class="nav-number">2.5.1.</span> <span class="nav-text">Heuristic algorithms</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Random-search"><span class="nav-number">2.5.2.</span> <span class="nav-text">Random search</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Algorithms"><span class="nav-number">2.6.</span> <span class="nav-text">Algorithms</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Chapter-2-Preliminary"><span class="nav-number">3.</span> <span class="nav-text">Chapter 2 - Preliminary</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Curve-Fitting-and-Regularization"><span class="nav-number">3.1.</span> <span class="nav-text">Curve Fitting and Regularization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Probabilities-Theory"><span class="nav-number">3.2.</span> <span class="nav-text">Probabilities Theory</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Basic-Concepts"><span class="nav-number">3.2.1.</span> <span class="nav-text">Basic Concepts</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Gaussian-Distribution"><span class="nav-number">3.2.2.</span> <span class="nav-text">Gaussian Distribution</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Likelihood-Function"><span class="nav-number">3.2.3.</span> <span class="nav-text">Likelihood Function</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Properties-of-mu-ML-and-sigma-2-ML"><span class="nav-number">3.2.4.</span> <span class="nav-text">Properties of $\mu_{ML}$ and $\sigma^2_{ML}$</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Curve-fitting-re-visited"><span class="nav-number">3.2.5.</span> <span class="nav-text">Curve fitting re-visited</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MAP-Maximum-Posteriori"><span class="nav-number">3.2.6.</span> <span class="nav-text">MAP: Maximum Posteriori</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="咕桃"
      src="https://avatars.githubusercontent.com/u/109007949?v=4">
  <p class="site-author-name" itemprop="name">咕桃</p>
  <div class="site-description" itemprop="description">Just Do It, But Not Just Do It.</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">39</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/GuTaoZi" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;GuTaoZi" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:first_fan@outlook.com" title="E-Mail → mailto:first_fan@outlook.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">咕桃</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


</body>
</html>
